{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458744cd-e2db-463e-a419-0ad9e6145e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bdse111.example.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>maggie</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f67a480c610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3706663a-2717-490c-8787-adaf1af62898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.functions import array_max\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "# from model.TimeBasedCV import TimeBasedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e94b47e-b307-4b85-9c1e-85056953d516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", True)\n",
    "ps.set_option(\"compute.default_index_type\", \"distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71f5416-468d-48ff-9a59-c12a5ca92041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'512m'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.kryoserializer.buffer.max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86df3eb-b7e1-4828-8b20-0013daeb4d64",
   "metadata": {},
   "source": [
    "# model.TimeBasedCV (pandas on Spark版本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160c7482-b387-48db-8c05-d23986587c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "class TimeBasedCV(object):\n",
    "    '''\n",
    "    Parameters \n",
    "    ----------\n",
    "    train_period: int\n",
    "        number of time units to include in each train set\n",
    "        default is 30\n",
    "    test_period: int\n",
    "        number of time units to include in each test set\n",
    "        default is 7\n",
    "    freq: string\n",
    "        frequency of input parameters. possible values are: days, months, years, weeks, hours, minutes, seconds\n",
    "        possible values designed to be used by dateutil.relativedelta class\n",
    "        deafault is days\n",
    "    '''\n",
    "         \n",
    "    def split(self, date_column,train_period=30, test_period=7, gap=0, stride=0,show_progress=False):\n",
    "        '''\n",
    "        Generate indices to split date_column into training and test set\n",
    "        \n",
    "        Parameters \n",
    "        ----------\n",
    "        date_column: string, deafult='record_date'\n",
    "            date of each record\n",
    "        gap: int, default=0\n",
    "            for cases the test set does not come right after the train set,\n",
    "            *gap* days are left between train and test sets\n",
    "        stride: int, default=0\n",
    "        \n",
    "        \n",
    "        Returns \n",
    "        -------\n",
    "        train_index ,test_index: \n",
    "            list of tuples (train index, test index) similar to sklearn model selection\n",
    "        '''\n",
    "                    \n",
    "        train_indices_list = []\n",
    "        test_indices_list = []\n",
    "        test_date_list = []\n",
    "        \n",
    "        # end_test = datetime.strptime(date_column.max(), \"%Y-%m-%d\")\n",
    "        end_test = date_column.max()\n",
    "        start_test = end_test - relativedelta(days=test_period)\n",
    "        end_train = start_test - relativedelta(days=gap)\n",
    "        start_train = end_train - relativedelta(days=train_period)\n",
    "        \n",
    "\n",
    "        while start_train > date_column.min():\n",
    "            # train indices:\n",
    "            # cur_train_indices = list(date_column[(date_column['t_dat']>=start_train) & (date_column['t_dat']<end_train)].index)\n",
    "            cur_train_indices = (date_column[(date_column>=start_train) & (date_column<end_train)].index).to_numpy()\n",
    "\n",
    "            # test indices:\n",
    "            cur_test_indices = (date_column[(date_column>=start_test) &\n",
    "                                    (date_column<end_test)].index).to_numpy()\n",
    "            \n",
    "            if(show_progress):\n",
    "                print(\"Train period:\",start_train,\"-\" , end_train, \", test period\", start_test, \"-\", end_test,\n",
    "                    \"# train records\", len(cur_train_indices), \", # test records\", len(cur_test_indices))\n",
    "\n",
    "            train_indices_list.append(cur_train_indices)\n",
    "            test_indices_list.append(cur_test_indices)\n",
    "            test_date_list.append(start_test)\n",
    "            \n",
    "            # update dates:\n",
    "            end_test = end_test - relativedelta(days=stride)\n",
    "            start_test = end_test - relativedelta(days=test_period)\n",
    "            end_train = start_test - relativedelta(days=gap)\n",
    "            start_train = end_train - relativedelta(days=train_period)\n",
    "\n",
    "        # mimic sklearn output  \n",
    "        index_output = [(train,test,start_test) for train,test,start_test in zip(train_indices_list,test_indices_list,test_date_list)]\n",
    "\n",
    "        self.n_splits = len(index_output)\n",
    "        \n",
    "        return index_output\n",
    "    \n",
    "    \n",
    "    def get_n_splits(self):\n",
    "        \"\"\"Returns the number of splitting iterations in the cross-validator\n",
    "        Returns\n",
    "        -------\n",
    "        n_splits : int\n",
    "            Returns the number of splitting iterations in the cross-validator.\n",
    "        \"\"\"\n",
    "        return self.n_splits \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1bf7d-df89-4692-9435-e24f600ebb60",
   "metadata": {},
   "source": [
    "# 定義函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b58be-7057-4aac-9516-a9e5b280c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(dataTrain, dataTest, paras={}):\n",
    "    \n",
    "    # == 轉換成 model 需要的資料型態 ==\n",
    "    \n",
    "    model = # modelName(paras)\n",
    "    model.fit(dataTrain)\n",
    "    \n",
    "    map12= # 計算map12\n",
    "    \n",
    "    return map12\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace2342-f05b-443b-bd35-b37c2cc3e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split_hyperparameter_search(data):\n",
    "    paras = {\n",
    "        # 'para1' : para1.values[0],\n",
    "        # 'para2' : para2.values[0]\n",
    "    }\n",
    "    \n",
    "    dataTrain = # data最後七天之前\n",
    "    dataTest = # data最後七天\n",
    "    \n",
    "    map12 = train_and_evaluate_model(dataTrain, dataTest, paras)\n",
    "    \n",
    "    paras.update({\n",
    "        'date_x_paras_id' : data.date_x_paras_id.values[0],\n",
    "        'val_date' : data.val_date.values[0],\n",
    "        'map12' : map12\n",
    "    })\n",
    "    \n",
    "    results = pd.DataFrame([paras])\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4046929-6f7f-4db3-bf24-0c1d443b16c1",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4219df-8917-47d3-a655-cecac07830e5",
   "metadata": {},
   "source": [
    "## 1. 讀取檔案 /DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1431f87d-52d0-4c07-9609-ac6e977ea0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 讀取檔案\n",
    "customers = spark.read.option('header','true').parquet('/user/HM_parquet/customers.parquet')\n",
    "articles = spark.read.option('header','true').parquet('/user/HM_parquet/articles.parquet')\n",
    "transactions = spark.read.option('header','true').parquet('/user/HM_parquet/transactions_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a841413-2d9a-4f01-ba53-5d301b39082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15311ca4-a3f1-47e9-9edf-7c6ea83fbee7",
   "metadata": {},
   "source": [
    "## 2. 將customer_id(字串)轉為customer_index(整數) /DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634903ba-7100-4a88-9f24-7becc2e1c40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 將customers的customer_id轉為數字(buffer要增加到512m)\n",
    "toIndex = StringIndexer(inputCol=\"customer_id\", outputCol=\"customer_index\").fit(customers)\n",
    "customers = toIndex.transform(customers)\n",
    "# customers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2875dbbe-f263-4550-bca3-79c887a4901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將transactions的customer_id轉為數字\n",
    "transactions = toIndex.transform(transactions)\n",
    "# transactions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64ded3-e050-46e5-a4c2-cebf60cb422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66614e-1b55-43e3-a632-42d05d0be6ef",
   "metadata": {},
   "source": [
    "## 3. 作時間分割 /pandas on spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e876de-3af8-485d-a307-b9f6764a120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_column = transactions.select('t_dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303695f-f148-41eb-b517-b4bd8ee41d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_column.withColumn(\"add_one_month\", sf.date_add(date_column['t_dat'], 10)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6da83d-07b0-4a8a-8053-9e4e9b05089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_column_pd['t_dat'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345273c-5afd-4273-b86c-4b8087e0c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_train_indices = (date_column[(date_column['t_dat']>=\"2019-05-01\") & \n",
    "#                                      (date_column['t_dat']<\"2019-06-01\")].index).to_numpy()\n",
    "# cur_train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520332b8-51f9-411f-8e77-94fb3aca7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tran_ps = transactions.to_pandas_on_spark()\n",
    "# tran_ps.loc[85908936269]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87b581-ec38-47ce-9bb0-48cb47cb4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_train_indices = [(date_column['t_dat']>=\"2019-05-01\") & (date_column['t_dat']<\"2019-06-01\")]\n",
    "# tran_ps[cur_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d2b218-b7e3-4a06-b610-d4b8dae33974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把資料依據時間做time split\n",
    "tscv = TimeBasedCV()\n",
    "tran_ps = transactions.to_pandas_on_spark()\n",
    "date_column = tran_ps['t_dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c18a66a-b964-48bb-96c3-bfce07d6c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = date_column.max()\n",
    "# datetime.strptime(date, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f55419-f2db-4b7c-86a1-53fd17d33cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-08-16 - 2020-09-15 , test period 2020-09-15 - 2020-09-22 # train records 1123728 , # test records 233498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-07-17 - 2020-08-16 , test period 2020-08-16 - 2020-08-23 # train records 1275928 , # test records 234159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-06-17 - 2020-07-17 , test period 2020-07-17 - 2020-07-24 # train records 1787814 , # test records 284020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-05-18 - 2020-06-17 , test period 2020-06-17 - 2020-06-24 # train records 1455684 , # test records 549443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-04-18 - 2020-05-18 , test period 2020-05-18 - 2020-05-25 # train records 1105288 , # test records 374636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-03-19 - 2020-04-18 , test period 2020-04-18 - 2020-04-25 # train records 1249538 , # test records 253001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-02-18 - 2020-03-19 , test period 2020-03-19 - 2020-03-26 # train records 1057458 , # test records 206631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2020-01-19 - 2020-02-18 , test period 2020-02-18 - 2020-02-25 # train records 1039983 , # test records 229317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-12-20 - 2020-01-19 , test period 2020-01-19 - 2020-01-26 # train records 1071268 , # test records 237155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-11-20 - 2019-12-20 , test period 2019-12-20 - 2019-12-27 # train records 1251937 , # test records 278504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-10-21 - 2019-11-20 , test period 2019-11-20 - 2019-11-27 # train records 986138 , # test records 220402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-09-21 - 2019-10-21 , test period 2019-10-21 - 2019-10-28 # train records 1281787 , # test records 247178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-08-22 - 2019-09-21 , test period 2019-09-21 - 2019-09-28 # train records 1055251 , # test records 239251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-07-23 - 2019-08-22 , test period 2019-08-22 - 2019-08-29 # train records 1488830 , # test records 235190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-06-23 - 2019-07-23 , test period 2019-07-23 - 2019-07-30 # train records 1878096 , # test records 466895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-05-24 - 2019-06-23 , test period 2019-06-23 - 2019-06-30 # train records 1716422 , # test records 583976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-04-24 - 2019-05-24 , test period 2019-05-24 - 2019-05-31 # train records 1491556 , # test records 383761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-03-25 - 2019-04-24 , test period 2019-04-24 - 2019-05-01 # train records 1415884 , # test records 385095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-02-23 - 2019-03-25 , test period 2019-03-25 - 2019-04-01 # train records 1241920 , # test records 324525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-01-24 - 2019-02-23 , test period 2019-02-23 - 2019-03-02 # train records 1208692 , # test records 321840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2018-12-25 - 2019-01-24 , test period 2019-01-24 - 2019-01-31 # train records 1166188 , # test records 297629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2018-11-25 - 2018-12-25 , test period 2018-12-25 - 2019-01-01 # train records 1148433 , # test records 238692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2018-10-26 - 2018-11-25 , test period 2018-11-25 - 2018-12-02 # train records 1321599 , # test records 272399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2018-09-26 - 2018-10-26 , test period 2018-10-26 - 2018-11-02 # train records 1446890 , # test records 330397\n"
     ]
    }
   ],
   "source": [
    "train_period, test_period, stride = 30, 7, 30\n",
    "index_output = tscv.split(date_column=date_column, train_period=train_period, test_period=test_period, stride=stride,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9975ca-cb75-4256-bbff-df74fadcde9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd7554f5-ac3e-4488-84aa-b6f487edfd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.pandas.config import set_option, reset_option\n",
    "set_option(\"compute.ops_on_diff_frames\", True)\n",
    "\n",
    "train_index, test_index, start_test = index_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15cf790d-2ced-4a1b-b726-747063a87a12",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unexpected item type: <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1646\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected item type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(item))\n",
      "\u001b[0;31mTypeError\u001b[0m: unexpected item type: <class 'numpy.ndarray'>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 18:38:06,551 WARN nio.NioEventLoop: Selector.select() returned prematurely 512 times in a row; rebuilding Selector io.netty.channel.nio.SelectedSelectionKeySetSelector@208fe6c8.\n",
      "2022-03-26 18:38:06,554 WARN nio.NioEventLoop: Selector.select() returned prematurely 512 times in a row; rebuilding Selector io.netty.channel.nio.SelectedSelectionKeySetSelector@819cf63.\n",
      "2022-03-26 18:38:06,559 WARN nio.NioEventLoop: Selector.select() returned prematurely 512 times in a row; rebuilding Selector io.netty.channel.nio.SelectedSelectionKeySetSelector@6de0f35c.\n"
     ]
    }
   ],
   "source": [
    "transactions[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4daea46c-8d4d-464a-9f64-3e8e1f07bb1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 將transaction加上start_test欄位\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtransactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m[train_index]\u001b[38;5;241m.\u001b[39mstart_test\u001b[38;5;241m=\u001b[39m start_test\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "# 將transaction加上start_test欄位\n",
    "transactions[train_index].withColumn('start_test', sf.lit(start_test))\n",
    "# transactions[\"start_test\"].loc[test_index]= start_test\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d569194-20dc-46a4-baad-0f477ac06c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09954a-97cf-4900-b72c-8185ad6ce9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in index_output:\n",
    "    train_data = transactions.loc[train_index]\n",
    "    test_data = transactions.loc[test_index]\n",
    "    # 取得test開始日期\n",
    "    test_data.reset_index(inplace=True, drop=True)\n",
    "    start_test = test_data['t_dat'][0]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3260e8-a8f7-4ea0-9ef1-fab3934b9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_udf\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('date_x_paras_id', IntegerType(),True),\n",
    "        StructField('map12', FloatType(),True),\n",
    "        StructField('val_date', DateTime(),True),\n",
    "        StructField(\"para1\", IntegerType(), True),\n",
    "        StructField(\"para2\", IntegerType(), True)\n",
    "     ]\n",
    ")\n",
    "\n",
    "results = df.groupby('date_x_paras_id').applyInPandas(time_split_hyperparameter_search, schema)\n",
    "results.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
