{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458744cd-e2db-463e-a419-0ad9e6145e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bdse111.example.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>maggie</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff4814a9610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3706663a-2717-490c-8787-adaf1af62898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "import numpy as np\n",
    "import gc\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.functions import array_max\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.pandas.config import set_option, reset_option\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e94b47e-b307-4b85-9c1e-85056953d516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", True)\n",
    "ps.set_option(\"compute.default_index_type\", \"distributed\")\n",
    "set_option(\"compute.ops_on_diff_frames\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71f5416-468d-48ff-9a59-c12a5ca92041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'512m'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.kryoserializer.buffer.max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211e0ab-6b6c-4e2f-a7f0-48dde3c45262",
   "metadata": {},
   "source": [
    "# 1. 讀取檔案 => tran_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818ed44a-369c-4a67-a68a-aee7f5bf83ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 讀取檔案\n",
    "# customers = ps.read_parquet('/user/HM_parquet/customers.parquet')\n",
    "# articles = ps.read_parquet('/user/HM_parquet/articles.parquet')\n",
    "tran_ps = ps.read_parquet('/user/HM_parquet/transactions_train.parquet').drop(['price', 'sales_channel_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8881aeab-fa63-4d2f-8f4b-fc371e3ef2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>start_test</th>\n",
       "      <th>split_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85899345920</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>663713001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85899345921</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>541518023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85899345922</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>505221004</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85899345923</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>685687003</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85899345924</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>685687004</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t_dat                                                       customer_id  article_id start_test split_id\n",
       "85899345920  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318   663713001                    \n",
       "85899345921  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318   541518023                    \n",
       "85899345922  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2   505221004                    \n",
       "85899345923  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2   685687003                    \n",
       "85899345924  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2   685687004                    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tran_ps.set_index('t_dat',inplace=True)\n",
    "tran_ps['start_test'] = ''\n",
    "tran_ps['split_id'] = ''\n",
    "tran_ps.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66614e-1b55-43e3-a632-42d05d0be6ef",
   "metadata": {},
   "source": [
    "# 2. 作時間分割 tran_ps => split_data, split_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9079e109-bcd4-4284-a78c-e8f4b6fbcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data,train_period=30, test_period=7, stride=30,show_progress=False):\n",
    "    \n",
    "    split_data = ps.DataFrame(columns = ['t_dat','customer_id', 'article_id', 'split_id', 'start_test'])\n",
    "    \n",
    "\n",
    "    end_test = data['t_dat'].max()\n",
    "    start_test = end_test - relativedelta(days=test_period)\n",
    "    start_train = start_test - relativedelta(days=train_period)\n",
    "    split_id=0\n",
    "\n",
    "    while start_train >= data['t_dat'].min():\n",
    "\n",
    "        df = data.loc[start_train:end_test]\n",
    "        df['start_test']=start_test\n",
    "        df['split_id'] = split_id\n",
    "        split_data = ps.concat([split_data,df])\n",
    "\n",
    "        if(show_progress):\n",
    "            print(\"Split_id:\",split_id,\", Train period:\",start_train,\"-\" , start_test, \", test period\", start_test, \"-\", end_test)\n",
    "\n",
    "        # update dates:\n",
    "        end_test = end_test - relativedelta(days=stride)\n",
    "        start_test = end_test - relativedelta(days=test_period)\n",
    "        start_train = start_test - relativedelta(days=train_period)\n",
    "        split_id += 1\n",
    "    \n",
    "    return split_data, split_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e573f4-6c40-4cb0-a04c-2230ee9738ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:50:07,340 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:50:09,339 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:50:14,112 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:560)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:528)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n",
      "2022-03-28 20:50:27,323 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 0 , Train period: 2020-08-16 - 2020-09-15 , test period 2020-09-15 - 2020-09-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:50:28,137 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:50:33,032 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:50:44,528 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 1 , Train period: 2020-07-17 - 2020-08-16 , test period 2020-08-16 - 2020-08-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:50:46,670 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:50:50,720 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:01,033 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 2 , Train period: 2020-06-17 - 2020-07-17 , test period 2020-07-17 - 2020-07-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:51:02,466 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:06,941 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:17,997 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 3 , Train period: 2020-05-18 - 2020-06-17 , test period 2020-06-17 - 2020-06-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:51:18,721 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:23,195 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:34,271 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 4 , Train period: 2020-04-18 - 2020-05-18 , test period 2020-05-18 - 2020-05-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:51:35,059 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:39,362 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:49,705 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 5 , Train period: 2020-03-19 - 2020-04-18 , test period 2020-04-18 - 2020-04-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:51:50,758 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:51:55,011 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:04,252 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 6 , Train period: 2020-02-18 - 2020-03-19 , test period 2020-03-19 - 2020-03-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:52:04,875 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:09,413 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:20,210 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 7 , Train period: 2020-01-19 - 2020-02-18 , test period 2020-02-18 - 2020-02-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:52:21,421 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:25,765 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:35,935 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 8 , Train period: 2019-12-20 - 2020-01-19 , test period 2020-01-19 - 2020-01-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:52:36,753 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:40,997 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:50,846 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 9 , Train period: 2019-11-20 - 2019-12-20 , test period 2019-12-20 - 2019-12-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:52:51,606 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:52:56,432 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:06,941 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 10 , Train period: 2019-10-21 - 2019-11-20 , test period 2019-11-20 - 2019-11-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:53:07,681 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:11,908 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:21,101 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 11 , Train period: 2019-09-21 - 2019-10-21 , test period 2019-10-21 - 2019-10-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:53:22,339 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:26,645 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:36,910 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 12 , Train period: 2019-08-22 - 2019-09-21 , test period 2019-09-21 - 2019-09-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:53:37,663 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:41,946 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:50,693 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 13 , Train period: 2019-07-23 - 2019-08-22 , test period 2019-08-22 - 2019-08-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:53:51,365 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:53:55,692 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:04,429 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 14 , Train period: 2019-06-23 - 2019-07-23 , test period 2019-07-23 - 2019-07-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:54:05,128 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:09,396 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:18,360 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 15 , Train period: 2019-05-24 - 2019-06-23 , test period 2019-06-23 - 2019-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:54:19,050 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:23,932 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:34,773 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 16 , Train period: 2019-04-24 - 2019-05-24 , test period 2019-05-24 - 2019-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:54:35,435 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:39,829 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:50,007 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 17 , Train period: 2019-03-25 - 2019-04-24 , test period 2019-04-24 - 2019-05-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:54:50,690 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:54:54,922 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:55:03,779 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split_id: 18 , Train period: 2019-02-23 - 2019-03-25 , test period 2019-03-25 - 2019-04-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:55:04,691 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-03-28 20:55:09,132 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 1) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m split_data, split_id \u001b[38;5;241m=\u001b[39m \u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtran_ps\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(data, train_period, test_period, stride, show_progress)\u001b[0m\n\u001b[1;32m      9\u001b[0m split_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_train \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_dat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin():\n\u001b[0;32m---> 13\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_train\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_test\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mstart_test\n\u001b[1;32m     15\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m split_id\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/pandas/indexing.py:473\u001b[0m, in \u001b[0;36mLocIndexerLike.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    470\u001b[0m     psdf[temp_col] \u001b[38;5;241m=\u001b[39m rows_sel\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(psdf)[psdf[temp_col], cols_sel][\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psdf_or_psser\u001b[38;5;241m.\u001b[39mcolumns)]\n\u001b[0;32m--> 473\u001b[0m cond, limit, remaining_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows_sel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m (\n\u001b[1;32m    475\u001b[0m     column_labels,\n\u001b[1;32m    476\u001b[0m     data_spark_columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m     series_name,\n\u001b[1;32m    480\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_cols(cols_sel)\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m returns_series:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/pandas/indexing.py:269\u001b[0m, in \u001b[0;36mLocIndexerLike._select_rows\u001b[0;34m(self, rows_sel)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rows_sel \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;66;03m# If slice is None - select everything, so nothing to do\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_rows_by_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows_sel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rows_sel, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_rows_else(rows_sel)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/pandas/indexing.py:1047\u001b[0m, in \u001b[0;36mLocIndexer._select_rows_by_slice\u001b[0;34m(self, rows_sel)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# if index order is not monotonic increasing or decreasing\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# and specified values don't exist in index, raise KeyError\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m rows_sel\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1044\u001b[0m     stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m rows_sel\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m ):\n\u001b[0;32m-> 1047\u001b[0m     inc \u001b[38;5;241m=\u001b[39m \u001b[43mindex_column\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_monotonic_increasing\u001b[49m\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m         dec \u001b[38;5;241m=\u001b[39m index_column\u001b[38;5;241m.\u001b[39mis_monotonic_decreasing\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/pandas/base.py:597\u001b[0m, in \u001b[0;36mIndexOpsMixin.is_monotonic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_monotonic\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m    Return boolean if values in the object are monotonically increasing.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_monotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mincreasing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/pandas/base.py:741\u001b[0m, in \u001b[0;36mIndexOpsMixin._is_monotonic\u001b[0;34m(self, order)\u001b[0m\n\u001b[1;32m    732\u001b[0m     comparison_col \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__partition_min\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlag(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__partition_max\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mover(\n\u001b[1;32m    733\u001b[0m         window\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    736\u001b[0m sdf \u001b[38;5;241m=\u001b[39m sdf\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m    737\u001b[0m     comparison_col\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__comparison_between_partitions\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    738\u001b[0m     F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__comparison_within_partition\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    739\u001b[0m )\n\u001b[0;32m--> 741\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43msdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__comparison_between_partitions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__comparison_within_partition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:693\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc) \u001b[38;5;28;01mas\u001b[39;00m css:\n\u001b[0;32m--> 693\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(PickleSerializer())))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    476\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "split_data, split_id = split(tran_ps,30,7,30,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ff57c-714a-4013-abba-83622e50ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7446fe7-8a98-4d3b-95df-804cf4a96186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 20:55:21,213 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "split_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e081df-ce79-4d81-a63a-834864bdebc2",
   "metadata": {},
   "source": [
    "# 3. 製作參數表 split_id => para_cross_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af31c0-2956-45eb-a010-48ba1131c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 製作參數表 paras_grid\n",
    "from itertools import product\n",
    "\n",
    "paras = list(\n",
    "    product(\n",
    "        [25,50,100,150,200],\n",
    "        [20,30,40,50],\n",
    "        [0.01]\n",
    "    )\n",
    ")\n",
    "paras_grid = ps.DataFrame(paras,columns= ['n_factors','n_epochs','reg_all'])\n",
    "paras_grid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e5a00-8133-411d-ad2f-d8555769b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 製作 split_id 表\n",
    "split_id_ps = ps.DataFrame({'split_id': range(split_id)})\n",
    "split_id_ps.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7042a73-b886-4c89-bc11-fe0d58390b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 paras_grid 與 split_id 做 cross join\n",
    "paras_grid['key'] = 1\n",
    "split_id_ps['key'] = 1\n",
    "\n",
    "para_cross_split = ps.merge(paras_grid, split_id_ps, on ='key').drop('key')\n",
    "del split_id_ps\n",
    "len(para_cross_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b85df-084a-4fe9-92ab-593bd6a3735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 cross join 後的表新增遞增的 group_id 欄位，之後要用來做 pandas_udf 的 groupby\n",
    "para_cross_split['group_id'] = 0\n",
    "para_cross_split['group_id'] = np.arange(len(para_cross_split)).tolist()\n",
    "para_cross_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927c99b-a1fd-4bca-b668-bb5239402a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_cross_split.to_parquet('/user/HM_parquet/SVD_model/para_cross_split.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e237f52-9033-4e3d-bca3-01f15621a19a",
   "metadata": {},
   "source": [
    "# 4. join 參數表和資料表 split_data, para_cross_split => join_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8cc8e2-ab37-4c93-9d2c-94ba36426f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data = split_data.join(para_cross_split.set_index('split_id'), on='split_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0e02c-c4c8-4c35-b05d-2a3773404c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c57b7-32ce-472e-ba18-6a39d15d5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data.to_parquet('/user/HM_parquet/SVD_model/join_data30.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5c883-13c7-4909-b4d5-2f6b6c9906f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del split_data, para_cross_split\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663284c-fce2-4991-a5bd-fffb5dfa35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a46e2e-743b-4096-83d9-2ead5d1d7174",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. surpriseSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a81400-b881-4dff-9e0f-7b5f542b3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp,SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import ml_metrics as metrics\n",
    "\n",
    "class surpriseSVD():\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "\n",
    "    def get_top_n(self, predictions, n=12):\n",
    "        \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "        Args:\n",
    "            predictions(list of Prediction objects): The list of predictions, as\n",
    "                returned by the test method of an algorithm.\n",
    "            n(int): The number of recommendation to output for each user. Default\n",
    "                is 10.\n",
    "        Returns:\n",
    "        A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "            [(raw item id, rating estimation), ...] of size n.\n",
    "        \"\"\"\n",
    "\n",
    "        # First map the predictions to each user.\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "\n",
    "        # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "\n",
    "        return top_n\n",
    "\n",
    "    def get_set(self,df):\n",
    "        reader = Reader(rating_scale=(1, 500))\n",
    "        data_set = Dataset.load_from_df(df[['customer_id','article_id','rating']], reader)\n",
    "        return data_set\n",
    "\n",
    "    def get_rating_set(self,df):\n",
    "        rating = df[['customer_id','article_id','price']].groupby(['customer_id','article_id']).count().reset_index()\n",
    "        rating.columns = ['customer_id','article_id','rating']\n",
    "        rating_set = self.get_set(rating)\n",
    "        return rating_set\n",
    "\n",
    "\n",
    "    def train_SVD(self, dataTrain, dataTest, paras={}):\n",
    "\n",
    "        ## 讀取評分資料為surprise可以訓練的格式\n",
    "        trainset = self.get_rating_set(train_data)\n",
    "        testset = self.get_rating_set(test_data)\n",
    "\n",
    "        ## rmse 需要的資料\n",
    "        testset2 = [testset.df.loc[i].to_list() for i in range(len(testset.df))]\n",
    "\n",
    "        ## map@k testing 需要產的資料\n",
    "        test_data.loc[:,'rating']=0\n",
    "        test_processed = self.get_set(test_data)\n",
    "        NA, test2 = train_test_split(test_processed, test_size=1.0)\n",
    "\n",
    "        # ======= 消費者的實際購買清單 =======\n",
    "        test_data['article_id'] = test_data['article_id'].astype('str')\n",
    "        test_uni = test_data.drop_duplicates(subset=['customer_id', 'article_id'], keep='first')\n",
    "        buy_n = test_uni[['customer_id','article_id']].groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "        cust_actual_list = []\n",
    "        for uid, user_ratings in buy_n.items():\n",
    "            cust_pred_tuple = (uid, [iid for iid in user_ratings])\n",
    "            cust_actual_list.append(cust_pred_tuple)\n",
    "\n",
    "        # ======= 訓練 SVD 模型 =======\n",
    "        algo = SVD(random_state=42,**paras)\n",
    "\n",
    "        # 訓練模型\n",
    "        algo.fit(trainset.build_full_trainset())\n",
    "\n",
    "        ##### rmse #####\n",
    "        predictions = algo.test(testset2)\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "\n",
    "        ##### map@k #####\n",
    "        predictions_map = algo.test(test2)\n",
    "        # est = [i.est for i in predictions_map] \n",
    "\n",
    "        ##  消費者的預測清單 \n",
    "        top_n = self.get_top_n(predictions=predictions_map, n=12)\n",
    "\n",
    "        cust_pred_list = []\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            cust_pred_tuple = (uid, [str(iid) for (iid, _) in user_ratings])\n",
    "            cust_pred_list.append(cust_pred_tuple)\n",
    "\n",
    "        final_list = list(zip(cust_actual_list, cust_pred_list))\n",
    "\n",
    "        # map@k計算 \n",
    "        mapk_list = []\n",
    "        for i in range(len(final_list)):\n",
    "            map_k = metrics.mapk([final_list[i][0][1]],[final_list[i][1][1]],12)\n",
    "            mapk_list.append(map_k)\n",
    "\n",
    "        map_k = sum(mapk_list)/len(mapk_list)\n",
    "\n",
    "        return rmse, map_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6af06-e9bb-4765-98eb-eef519527caf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870d90a-9d08-435a-9162-64ec63bd33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(d) -> bool:\n",
    "    return (d['t_dat'] <= d['start_test'])\n",
    "\n",
    "train_index = split_data.apply(get_train, axis=1)\n",
    "train_index\n",
    "# split_data[train_index].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace2342-f05b-443b-bd35-b37c2cc3e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split_hyperparameter_search(data):\n",
    "    paras = {\n",
    "        'factors':data.factors.values[0], \n",
    "        'iterations':dta.iterations.values[0], \n",
    "        'regularization':data.regularization.values[0]\n",
    "    }\n",
    "    \n",
    "    dataTrain = data[(data['t_dat'] <= data['start_test'])]\n",
    "    dataTest = data[(data['t_dat'] > start_test)]\n",
    "    \n",
    "    rmse, map12 = model.train_SVD(dataTrain, dataTest, paras)\n",
    "    \n",
    "    paras.update({\n",
    "        'date_x_paras_id' : data.date_x_paras_id.values[0],\n",
    "        'val_date' : data.val_date.values[0],\n",
    "        'map12' : map12\n",
    "    })\n",
    "    \n",
    "    results = pd.DataFrame([paras])\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3260e8-a8f7-4ea0-9ef1-fab3934b9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_udf\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('date_x_paras_id', IntegerType(),True),\n",
    "        StructField('map12', FloatType(),True),\n",
    "        StructField('val_date', DateTime(),True),\n",
    "        StructField(\"para1\", IntegerType(), True),\n",
    "        StructField(\"para2\", IntegerType(), True)\n",
    "     ]\n",
    ")\n",
    "\n",
    "results = df.groupby('date_x_paras_id').applyInPandas(time_split_hyperparameter_search, schema)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5348c4-3990-44eb-84b9-2eed404cc61b",
   "metadata": {},
   "source": [
    "# (DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b996c3-1b5e-4f11-8776-c5a589f457b2",
   "metadata": {},
   "source": [
    "## 1. 讀取檔案 /DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431f87d-52d0-4c07-9609-ac6e977ea0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 讀取檔案\n",
    "# customers = spark.read.option('header','true').parquet('/user/HM_parquet/customers.parquet')\n",
    "# articles = spark.read.option('header','true').parquet('/user/HM_parquet/articles.parquet')\n",
    "# transactions = spark.read.option('header','true').parquet('/user/HM_parquet/transactions_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a841413-2d9a-4f01-ba53-5d301b39082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012b563-2eb7-40c8-8d2a-39a119f9e288",
   "metadata": {},
   "source": [
    "## 2. 將customer_id(字串)轉為customer_index(整數) /DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634903ba-7100-4a88-9f24-7becc2e1c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 將customers的customer_id轉為數字(buffer要增加到512m)\n",
    "# toIndex = StringIndexer(inputCol=\"customer_id\", outputCol=\"customer_index\").fit(customers)\n",
    "# customers = toIndex.transform(customers)\n",
    "# # customers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875dbbe-f263-4550-bca3-79c887a4901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 將transactions的customer_id轉為數字\n",
    "# transactions = toIndex.transform(transactions)\n",
    "# # transactions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64ded3-e050-46e5-a4c2-cebf60cb422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
