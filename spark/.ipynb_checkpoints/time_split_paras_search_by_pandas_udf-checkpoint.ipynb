{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee3d7fd-c0c3-47bf-820b-cb2b94e70908",
   "metadata": {},
   "source": [
    "# 0. 設定 Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458744cd-e2db-463e-a419-0ad9e6145e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bdse111.example.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>maggie</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1164dc0610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3706663a-2717-490c-8787-adaf1af62898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "import numpy as np\n",
    "import gc\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import array_max\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.pandas.config import set_option, reset_option\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e94b47e-b307-4b85-9c1e-85056953d516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", True)\n",
    "ps.set_option(\"compute.default_index_type\", \"distributed\")\n",
    "set_option(\"compute.ops_on_diff_frames\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71f5416-468d-48ff-9a59-c12a5ca92041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'512m'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.kryoserializer.buffer.max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211e0ab-6b6c-4e2f-a7f0-48dde3c45262",
   "metadata": {},
   "source": [
    "# 1. 讀取檔案 => tran_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ed44a-369c-4a67-a68a-aee7f5bf83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取檔案\n",
    "# customers = ps.read_parquet('/user/HM_parquet/customers.parquet')\n",
    "# articles = ps.read_parquet('/user/HM_parquet/articles.parquet')\n",
    "tran_ps = ps.read_parquet('/user/HM_parquet/transactions_train.parquet').drop(['price', 'sales_channel_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881aeab-fa63-4d2f-8f4b-fc371e3ef2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_ps.set_index('t_dat',inplace=True)\n",
    "tran_ps['start_test'] = ''\n",
    "tran_ps['split_id'] = ''\n",
    "tran_ps.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66614e-1b55-43e3-a632-42d05d0be6ef",
   "metadata": {},
   "source": [
    "# 2. 作時間分割 tran_ps => split_data, split_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079e109-bcd4-4284-a78c-e8f4b6fbcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data,train_period=30, test_period=7, stride=30,show_progress=False):\n",
    "    \n",
    "    split_data = ps.DataFrame(columns = ['t_dat','customer_id', 'article_id', 'split_id', 'start_test']).set_index('t_dat',inplace=True)\n",
    "\n",
    "    end_test = data.index.max()\n",
    "    start_test = end_test - relativedelta(days=test_period)\n",
    "    start_train = start_test - relativedelta(days=train_period)\n",
    "    split_id=0\n",
    "\n",
    "    while start_train >= data.index.min():\n",
    "\n",
    "        df = data.loc[start_train:end_test]\n",
    "        df['start_test']=start_test\n",
    "        df['split_id'] = split_id\n",
    "        split_data = ps.concat([split_data,df])\n",
    "\n",
    "        if(show_progress):\n",
    "            print(\"Split_id:\",split_id,\", Train period:\",start_train,\"-\" , start_test, \", test period\", start_test, \"-\", end_test)\n",
    "\n",
    "        # update dates:\n",
    "        end_test = end_test - relativedelta(days=stride)\n",
    "        start_test = end_test - relativedelta(days=test_period)\n",
    "        start_train = start_test - relativedelta(days=train_period)\n",
    "        split_id += 1\n",
    "    \n",
    "    return split_data, split_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e573f4-6c40-4cb0-a04c-2230ee9738ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data, split_id = split(tran_ps,30,7,30,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7446fe7-8a98-4d3b-95df-804cf4a96186",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ff57c-714a-4013-abba-83622e50ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e081df-ce79-4d81-a63a-834864bdebc2",
   "metadata": {},
   "source": [
    "# 3. 製作參數表 split_id => para_cross_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af31c0-2956-45eb-a010-48ba1131c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 製作參數表 paras_grid\n",
    "from itertools import product\n",
    "\n",
    "paras = list(\n",
    "    product(\n",
    "        [25,50,100,150,200],\n",
    "        [20,30,40,50],\n",
    "        [0.01]\n",
    "    )\n",
    ")\n",
    "paras_grid = ps.DataFrame(paras,columns= ['n_factors','n_epochs','reg_all'])\n",
    "paras_grid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e5a00-8133-411d-ad2f-d8555769b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 製作 split_id 表\n",
    "split_id_ps = ps.DataFrame({'split_id': range(split_id)})\n",
    "split_id_ps.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7042a73-b886-4c89-bc11-fe0d58390b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 paras_grid 與 split_id 做 cross join\n",
    "paras_grid['key'] = 1\n",
    "split_id_ps['key'] = 1\n",
    "\n",
    "para_cross_split = ps.merge(paras_grid, split_id_ps, on ='key').drop('key')\n",
    "del split_id_ps\n",
    "len(para_cross_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b85df-084a-4fe9-92ab-593bd6a3735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 cross join 後的表新增遞增的 group_id 欄位，之後要用來做 pandas_udf 的 groupby\n",
    "para_cross_split['group_id'] = 0\n",
    "para_cross_split['group_id'] = np.arange(len(para_cross_split)).tolist()\n",
    "para_cross_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927c99b-a1fd-4bca-b668-bb5239402a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para_cross_split.to_parquet('/user/HM_parquet/SVD_model/para_cross_split.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e237f52-9033-4e3d-bca3-01f15621a19a",
   "metadata": {},
   "source": [
    "# 4. join 參數表和資料表 split_data, para_cross_split => join_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8cc8e2-ab37-4c93-9d2c-94ba36426f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data = split_data.join(para_cross_split.set_index('split_id'), on='split_id')\n",
    "join_data.set_index('t_dat',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0e02c-c4c8-4c35-b05d-2a3773404c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cace0df-e8bc-4310-ad49-4c8aefd26373",
   "metadata": {},
   "outputs": [],
   "source": [
    "39919883*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a348c3-df01-4ea8-8c4f-1831f2a73da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c57b7-32ce-472e-ba18-6a39d15d5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join_data.to_parquet('/user/HM_parquet/SVD_model/join_data30.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5c883-13c7-4909-b4d5-2f6b6c9906f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除用不到的資料表\n",
    "del split_data, para_cross_split\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347efaa-1f3b-4ca9-a904-6f13017347f1",
   "metadata": {},
   "source": [
    "# -----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567ccf7-b7a6-49f0-b995-d48fe917c7bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 讀取資料表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab23a46-83fa-4cbd-9bd9-080f004a65da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customer_id    798397660\n",
       "group_id       798397660\n",
       "n_epochs       798397660\n",
       "article_id     798397660\n",
       "n_factors      798397660\n",
       "reg_all        798397660\n",
       "split_id       798397660\n",
       "start_test     798397660\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_data = ps.read_parquet('/user/HM_parquet/SVD_model/join_data30.parquet')\n",
    "join_data.set_index('t_dat',inplace=True)\n",
    "join_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21d9cdb-574b-45a1-8386-9eb84b26a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>start_test</th>\n",
       "      <th>n_factors</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>reg_all</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_dat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>17</td>\n",
       "      <td>000ae8a03447710b4de81d85698dfc0559258c93136650...</td>\n",
       "      <td>695632015</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>17</td>\n",
       "      <td>000ae8a03447710b4de81d85698dfc0559258c93136650...</td>\n",
       "      <td>695632015</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>17</td>\n",
       "      <td>000ae8a03447710b4de81d85698dfc0559258c93136650...</td>\n",
       "      <td>695632015</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>17</td>\n",
       "      <td>000ae8a03447710b4de81d85698dfc0559258c93136650...</td>\n",
       "      <td>695632015</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>17</td>\n",
       "      <td>000ae8a03447710b4de81d85698dfc0559258c93136650...</td>\n",
       "      <td>695632015</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            split_id                                                       customer_id  article_id  start_test  n_factors  n_epochs  reg_all  group_id\n",
       "t_dat                                                                                                                                                 \n",
       "2019-03-25        17  000ae8a03447710b4de81d85698dfc0559258c93136650efc2429fcca80d699a   695632015  2019-04-24         25        20     0.01        17\n",
       "2019-03-25        17  000ae8a03447710b4de81d85698dfc0559258c93136650efc2429fcca80d699a   695632015  2019-04-24         50        50     0.01       185\n",
       "2019-03-25        17  000ae8a03447710b4de81d85698dfc0559258c93136650efc2429fcca80d699a   695632015  2019-04-24        100        20     0.01       209\n",
       "2019-03-25        17  000ae8a03447710b4de81d85698dfc0559258c93136650efc2429fcca80d699a   695632015  2019-04-24        100        30     0.01       233\n",
       "2019-03-25        17  000ae8a03447710b4de81d85698dfc0559258c93136650efc2429fcca80d699a   695632015  2019-04-24        100        40     0.01       257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a46e2e-743b-4096-83d9-2ead5d1d7174",
   "metadata": {
    "tags": []
   },
   "source": [
    "# surpriseSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28e91e2-3a99-4c74-aaee-48c77379a502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting surprise\n",
      "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Collecting scikit-surprise\n",
      "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.22.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from scikit-surprise->surprise) (1.14.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp38-cp38-linux_x86_64.whl size=2324463 sha256=76705ac38914995cf421f5fd68887b977a9dc3e6c70cbf1b5d6bb42cd484baf6\n",
      "  Stored in directory: /home/hadoop/.cache/pip/wheels/20/91/57/2965d4cff1b8ac7ed1b6fa25741882af3974b54a31759e10b6\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "\u001b[33m  WARNING: The script surprise is installed in '/home/hadoop/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed scikit-surprise-1.1.1 surprise-0.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a81400-b881-4dff-9e0f-7b5f542b3445",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from surprise import NormalPredictor\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVDpp,SVD\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp,SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import ml_metrics as metrics\n",
    "\n",
    "class surpriseSVD():\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "\n",
    "    def get_top_n(self, predictions, n=12):\n",
    "        \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "        Args:\n",
    "            predictions(list of Prediction objects): The list of predictions, as\n",
    "                returned by the test method of an algorithm.\n",
    "            n(int): The number of recommendation to output for each user. Default\n",
    "                is 10.\n",
    "        Returns:\n",
    "        A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "            [(raw item id, rating estimation), ...] of size n.\n",
    "        \"\"\"\n",
    "\n",
    "        # First map the predictions to each user.\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "\n",
    "        # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "\n",
    "        return top_n\n",
    "\n",
    "    def get_set(self,df):\n",
    "        reader = Reader(rating_scale=(1, 500))\n",
    "        data_set = Dataset.load_from_df(df[['customer_id','article_id','rating']], reader)\n",
    "        return data_set\n",
    "\n",
    "    def get_rating_set(self,df):\n",
    "        rating = df[['customer_id','article_id','price']].groupby(['customer_id','article_id']).count().reset_index()\n",
    "        rating.columns = ['customer_id','article_id','rating']\n",
    "        rating_set = self.get_set(rating)\n",
    "        return rating_set\n",
    "\n",
    "\n",
    "    def train_SVD(self, dataTrain, dataTest, paras={}):\n",
    "\n",
    "        ## 讀取評分資料為surprise可以訓練的格式\n",
    "        trainset = self.get_rating_set(train_data)\n",
    "        testset = self.get_rating_set(test_data)\n",
    "\n",
    "        ## rmse 需要的資料\n",
    "        testset2 = [testset.df.loc[i].to_list() for i in range(len(testset.df))]\n",
    "\n",
    "        ## map@k testing 需要產的資料\n",
    "        test_data.loc[:,'rating']=0\n",
    "        test_processed = self.get_set(test_data)\n",
    "        NA, test2 = train_test_split(test_processed, test_size=1.0)\n",
    "\n",
    "        # ======= 消費者的實際購買清單 =======\n",
    "        test_data['article_id'] = test_data['article_id'].astype('str')\n",
    "        test_uni = test_data.drop_duplicates(subset=['customer_id', 'article_id'], keep='first')\n",
    "        buy_n = test_uni[['customer_id','article_id']].groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "        cust_actual_list = []\n",
    "        for uid, user_ratings in buy_n.items():\n",
    "            cust_pred_tuple = (uid, [iid for iid in user_ratings])\n",
    "            cust_actual_list.append(cust_pred_tuple)\n",
    "\n",
    "        # ======= 訓練 SVD 模型 =======\n",
    "        algo = SVD(random_state=42,**paras)\n",
    "\n",
    "        # 訓練模型\n",
    "        algo.fit(trainset.build_full_trainset())\n",
    "\n",
    "        ##### rmse #####\n",
    "        predictions = algo.test(testset2)\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "\n",
    "        ##### map@k #####\n",
    "        predictions_map = algo.test(test2)\n",
    "        # est = [i.est for i in predictions_map] \n",
    "\n",
    "        ##  消費者的預測清單 \n",
    "        top_n = self.get_top_n(predictions=predictions_map, n=12)\n",
    "\n",
    "        cust_pred_list = []\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            cust_pred_tuple = (uid, [str(iid) for (iid, _) in user_ratings])\n",
    "            cust_pred_list.append(cust_pred_tuple)\n",
    "\n",
    "        final_list = list(zip(cust_actual_list, cust_pred_list))\n",
    "\n",
    "        # map@k計算 \n",
    "        mapk_list = []\n",
    "        for i in range(len(final_list)):\n",
    "            map_k = metrics.mapk([final_list[i][0][1]],[final_list[i][1][1]],12)\n",
    "            mapk_list.append(map_k)\n",
    "\n",
    "        map_k = sum(mapk_list)/len(mapk_list)\n",
    "\n",
    "        return rmse, map_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6af06-e9bb-4765-98eb-eef519527caf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba028f-5482-4201-9e2d-0a3979e749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tran_ps = ps.read_parquet('/user/HM_parquet/transactions_train.parquet').drop(['price', 'sales_channel_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0dafd-f8ce-4c20-81da-0405b2ed28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [True, False, False, True]\n",
    "not t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870d90a-9d08-435a-9162-64ec63bd33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(d) -> bool:\n",
    "    train_index = (d['t_dat'] <= d['start_test'])\n",
    "    test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace2342-f05b-443b-bd35-b37c2cc3e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split_hyperparameter_search(data):\n",
    "    paras = {\n",
    "        'factors':data.factors.values[0], \n",
    "        'iterations':dta.iterations.values[0], \n",
    "        'regularization':data.regularization.values[0]\n",
    "    }\n",
    "    \n",
    "    train_index = join_data.apply(get_train, axis=1)\n",
    "    dataTrain = data[(data['t_dat'] <= data['start_test'])]\n",
    "    dataTest = data[(data['t_dat'] > start_test)]\n",
    "    \n",
    "    rmse, map12 = model.train_SVD(dataTrain, dataTest, paras)\n",
    "    \n",
    "    paras.update({\n",
    "        'date_x_paras_id' : data.date_x_paras_id.values[0],\n",
    "        'val_date' : data.val_date.values[0],\n",
    "        'map12' : map12\n",
    "    })\n",
    "    \n",
    "    results = pd.DataFrame([paras])\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3260e8-a8f7-4ea0-9ef1-fab3934b9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_udf\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('date_x_paras_id', IntegerType(),True),\n",
    "        StructField('map12', FloatType(),True),\n",
    "        StructField('val_date', DateTime(),True),\n",
    "        StructField(\"para1\", IntegerType(), True),\n",
    "        StructField(\"para2\", IntegerType(), True)\n",
    "     ]\n",
    ")\n",
    "\n",
    "results = df.groupby('date_x_paras_id').applyInPandas(time_split_hyperparameter_search, schema)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5348c4-3990-44eb-84b9-2eed404cc61b",
   "metadata": {},
   "source": [
    "# (DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b996c3-1b5e-4f11-8776-c5a589f457b2",
   "metadata": {},
   "source": [
    "## 1. 讀取檔案 /DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431f87d-52d0-4c07-9609-ac6e977ea0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 讀取檔案\n",
    "# customers = spark.read.option('header','true').parquet('/user/HM_parquet/customers.parquet')\n",
    "# articles = spark.read.option('header','true').parquet('/user/HM_parquet/articles.parquet')\n",
    "# transactions = spark.read.option('header','true').parquet('/user/HM_parquet/transactions_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a841413-2d9a-4f01-ba53-5d301b39082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012b563-2eb7-40c8-8d2a-39a119f9e288",
   "metadata": {},
   "source": [
    "## 2. 將customer_id(字串)轉為customer_index(整數) /DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634903ba-7100-4a88-9f24-7becc2e1c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 將customers的customer_id轉為數字(buffer要增加到512m)\n",
    "# toIndex = StringIndexer(inputCol=\"customer_id\", outputCol=\"customer_index\").fit(customers)\n",
    "# customers = toIndex.transform(customers)\n",
    "# # customers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875dbbe-f263-4550-bca3-79c887a4901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 將transactions的customer_id轉為數字\n",
    "# transactions = toIndex.transform(transactions)\n",
    "# # transactions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64ded3-e050-46e5-a4c2-cebf60cb422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
