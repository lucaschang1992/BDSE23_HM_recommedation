{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import *\n",
    "from TimeBasedCV import TimeBasedCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet('../data/HM_parquet/transactions_train.parquet')\n",
    "customers = pd.read_parquet('../data/HM_parquet/customers.parquet')\n",
    "articles = pd.read_parquet('../data/HM_parquet/articles.parquet')\n",
    "\n",
    "tscv = TimeBasedCV(freq='days')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surprise.SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57mb6yRHhpuB"
   },
   "source": [
    "### 前置作業(安裝導入套件)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGdzFLT5huQb",
    "outputId": "2ec1b0f6-f228-4934-ded5-d15235d28f98"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp,SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate,GridSearchCV,train_test_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import ml_metrics as metrics\n",
    "\n",
    "def get_top_n(predictions, n=12):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "def get_rating(df):\n",
    "    rating = df[['customer_id','article_id','price']].groupby(['customer_id','article_id']).count().reset_index()\n",
    "    rating.columns = ['customer_id','article_id','rating']\n",
    "    return rating\n",
    "\n",
    "def data_preprocess(data):\n",
    "    data_rating = get_rating(data)\n",
    "    reader = Reader(rating_scale=(1, 500))\n",
    "    data_set = Dataset.load_from_df(data_rating[['customer_id','article_id','rating']], reader)\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試一個月的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試一個月的資料\n",
    "train_one_month = pd.read_parquet('../data/HM_parquet/train_one_month.parquet')\n",
    "val_one_month = pd.read_parquet('../data/HM_parquet/val_one_month.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 讀取評分資料為surprise可以訓練的格式\n",
    "trainset = data_preprocess(train_one_month)\n",
    "testset = data_preprocess(val_one_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4548\n",
      "{'factors': 25, 'iterations': 20, 'regularization': 0.01, 'rmse': 0.4548226270871537, 'map@k': 0.0006934235506988925}\n",
      "RMSE: 0.4567\n",
      "{'factors': 25, 'iterations': 30, 'regularization': 0.01, 'rmse': 0.45673652012935334, 'map@k': 0.0007755140243779781}\n",
      "RMSE: 0.4587\n",
      "{'factors': 25, 'iterations': 40, 'regularization': 0.01, 'rmse': 0.4586807454781601, 'map@k': 0.0006906737139759364}\n",
      "RMSE: 0.4607\n",
      "{'factors': 25, 'iterations': 50, 'regularization': 0.01, 'rmse': 0.4607378817159362, 'map@k': 0.0007664917950177387}\n",
      "RMSE: 0.4554\n",
      "{'factors': 50, 'iterations': 20, 'regularization': 0.01, 'rmse': 0.45544503589409663, 'map@k': 0.0005892022967062667}\n",
      "RMSE: 0.4573\n",
      "{'factors': 50, 'iterations': 30, 'regularization': 0.01, 'rmse': 0.45732918412556306, 'map@k': 0.0007298004467408034}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Student\\Documents\\git_workspace\\BDSE23_HM_recommendation\\model\\time_split_validation(SVD).ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=6'>7</a>\u001b[0m algo \u001b[39m=\u001b[39m SVD(n_factors \u001b[39m=\u001b[39m factors,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=7'>8</a>\u001b[0m            n_epochs\u001b[39m=\u001b[39miterations,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=8'>9</a>\u001b[0m            reg_all\u001b[39m=\u001b[39mregularization,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=9'>10</a>\u001b[0m            random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=11'>12</a>\u001b[0m \u001b[39m# 訓練模型\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=12'>13</a>\u001b[0m algo\u001b[39m.\u001b[39;49mfit(trainset\u001b[39m.\u001b[39;49mbuild_full_trainset())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=13'>14</a>\u001b[0m \u001b[39m# step3 - testing(train_test_split way)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=14'>15</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=15'>16</a>\u001b[0m \u001b[39m##### rmse #####\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/git_workspace/BDSE23_HM_recommendation/model/time_split_validation%28SVD%29.ipynb#ch0000030?line=16'>17</a>\u001b[0m testset2 \u001b[39m=\u001b[39m [testset\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mloc[i]\u001b[39m.\u001b[39mto_list() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(testset\u001b[39m.\u001b[39mdf))]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HM\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:155\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HM\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:231\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HM\\lib\\site-packages\\surprise\\trainset.py:189\u001b[0m, in \u001b[0;36mTrainset.all_ratings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Student/anaconda3/envs/HM/lib/site-packages/surprise/trainset.py?line=186'>187</a>\u001b[0m \u001b[39mfor\u001b[39;00m u, u_ratings \u001b[39min\u001b[39;00m iteritems(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mur):\n\u001b[0;32m    <a href='file:///c%3A/Users/Student/anaconda3/envs/HM/lib/site-packages/surprise/trainset.py?line=187'>188</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m u_ratings:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Student/anaconda3/envs/HM/lib/site-packages/surprise/trainset.py?line=188'>189</a>\u001b[0m         \u001b[39myield\u001b[39;00m u, i, r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 模型訓練與驗證(svd)\n",
    "scores = pd.DataFrame()\n",
    "for factors in [25,50,100,150,200]:\n",
    "    for iterations in [20,30,40,50]:\n",
    "        for regularization in [0.01]:\n",
    "\n",
    "            algo = SVD(n_factors = factors,\n",
    "                       n_epochs=iterations,\n",
    "                       reg_all=regularization,\n",
    "                       random_state=42)\n",
    "\n",
    "            # 訓練模型\n",
    "            algo.fit(trainset.build_full_trainset())\n",
    "            # step3 - testing(train_test_split way)\n",
    "            \n",
    "            ##### rmse #####\n",
    "            testset2 = [testset.df.loc[i].to_list() for i in range(len(testset.df))]\n",
    "            predictions = algo.test(testset2)\n",
    "            rmse = accuracy.rmse(predictions)\n",
    "\n",
    "            ## map@k testing需要產的資料\n",
    "            val_one_month.loc[:,'rating']=0\n",
    "            test_processed = Dataset.load_from_df(val_one_month[['customer_id','article_id','rating']], reader) \n",
    "            NA, test2 = train_test_split(test_processed, test_size=1.0)\n",
    "\n",
    "            ##### map@k #####\n",
    "            predictions_map = algo.test(test2)\n",
    "            # est = [i.est for i in predictions_map] \n",
    "\n",
    "            ## ======= 消費者的預測清單 =======\n",
    "            top_n = get_top_n(predictions_map, n=12)\n",
    "\n",
    "            cust_pred_list = []\n",
    "            for uid, user_ratings in top_n.items():\n",
    "                cust_pred_tuple = (uid, [str(iid) for (iid, _) in user_ratings])\n",
    "                cust_pred_list.append(cust_pred_tuple)\n",
    "            \n",
    "            # ======= 消費者的實際購買清單 =======\n",
    "            val_one_month['article_id'] = val_one_month['article_id'].astype('str')\n",
    "            test_uni = val_one_month.drop_duplicates(subset=['customer_id', 'article_id'], keep='first')\n",
    "            buy_n = test_uni[['customer_id','article_id']].groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "            cust_actual_list = []\n",
    "            for uid, user_ratings in buy_n.items():\n",
    "                cust_pred_tuple = (uid, [iid for iid in user_ratings])\n",
    "                cust_actual_list.append(cust_pred_tuple)\n",
    "\n",
    "            final_list = list(zip(cust_actual_list, cust_pred_list))\n",
    "            \n",
    "\n",
    "\n",
    "            #map@k計算 \n",
    "            mapk_list = []\n",
    "            for i in range(len(final_list)):\n",
    "              map_k = metrics.mapk([final_list[i][0][1]],[final_list[i][1][1]],12)\n",
    "              mapk_list.append(map_k)\n",
    "\n",
    "            def Average(lst):\n",
    "                return sum(lst) / len(lst)\n",
    "\n",
    "            map_k = Average(mapk_list)\n",
    "\n",
    "            newRow = {\n",
    "                        # =====填寫參數名稱===============\n",
    "                        'factors':factors, \n",
    "                        'iterations':iterations, \n",
    "                        'regularization':regularization, \n",
    "                        # ===============================\n",
    "                        'rmse':rmse,\n",
    "                        'map@k':map_k\n",
    "                        }\n",
    "            print(newRow)\n",
    "            newDF = pd.DataFrame([newRow])\n",
    "            scores = pd.concat([scores, newDF], axis=0 ,ignore_index=True)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_period, val_period, stride = 30, 7, 30\n",
    "scores_one_month = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "one_fold_scores = model.train_ALS(train_one_month, val_one_month, train_period, val_period, stride,start_val=0)\n",
    "scores_one_month = pd.concat([scores_one_month,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "scores_one_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_one_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分別取不同時間段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import *\n",
    "from model.TimeBasedCV import TimeBasedCV\n",
    "from model.ImplicitALS import ImplicitALS as als\n",
    "\n",
    "model = als()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet('data\\\\HM_parquet\\\\transactions_train.parquet')\n",
    "customers = pd.read_parquet('data\\\\HM_parquet\\\\customers.parquet')\n",
    "articles = pd.read_parquet('data\\\\HM_parquet\\\\articles.parquet')\n",
    "\n",
    "tscv = TimeBasedCV(freq='days')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = model.data_preprocess(transactions,customers,articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做 time based split 30天\n",
    "train_period, val_period, stride = 30, 7, 30\n",
    "index_output = tscv.split(transactions, date_column='t_dat', train_period=train_period, val_period=val_period, stride=stride,show_progress=True)\n",
    "\n",
    "# 做 time based CV\n",
    "scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "for train_index, val_index in index_output:\n",
    "    train_data = transactions.loc[train_index]\n",
    "    val_data = transactions.loc[val_index]\n",
    "    # 取得val開始日期\n",
    "    val_data.reset_index(inplace=True, drop=True)\n",
    "    start_val = val_data['t_dat'][0]\n",
    "    # 呼叫訓練模型的function\n",
    "    one_fold_scores = model.train_ALS(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "    scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "scores.to_parquet('model/params/params_stride30/implicit_ALS_train30.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做 time based split 60天\n",
    "train_period, val_period, stride = 60, 7, 30\n",
    "index_output = tscv.split(transactions, date_column='t_dat', train_period=train_period, val_period=val_period, stride=stride,show_progress=True)\n",
    "\n",
    "# 做 time based CV\n",
    "scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "for train_index, val_index in index_output:\n",
    "    train_data = transactions.loc[train_index]\n",
    "    val_data = transactions.loc[val_index]\n",
    "    # 取得val開始日期\n",
    "    val_data.reset_index(inplace=True, drop=True)\n",
    "    start_val = val_data['t_dat'][0]\n",
    "    # 呼叫訓練模型的function\n",
    "    one_fold_scores = model.train_ALS(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "    scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "# average_r2score = np.mean(scores)\n",
    "\n",
    "scores.to_parquet('model/params/params_stride30/implicit_ALS_train60.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做 time based split 90天\n",
    "train_period, val_period, stride = 90, 7, 30\n",
    "index_output = tscv.split(transactions, date_column='t_dat', train_period=train_period, val_period=val_period, stride=stride,show_progress=True)\n",
    "\n",
    "# 做 time based CV\n",
    "scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "for train_index, val_index in index_output:\n",
    "    train_data = transactions.loc[train_index]\n",
    "    val_data = transactions.loc[val_index]\n",
    "    # 取得val開始日期\n",
    "    val_data.reset_index(inplace=True, drop=True)\n",
    "    start_val = val_data['t_dat'][0]\n",
    "    # 呼叫訓練模型的function\n",
    "    one_fold_scores = model.train_ALS(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "    scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "# average_r2score = np.mean(scores)\n",
    "\n",
    "scores.to_parquet('model/params/params_stride30/implicit_ALS_train90.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做 time based split 180天\n",
    "train_period, val_period, stride = 180, 7, 30\n",
    "index_output = tscv.split(transactions, date_column='t_dat', train_period=train_period, val_period=val_period, stride=stride,show_progress=True)\n",
    "\n",
    "# 做 time based CV\n",
    "scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "for train_index, val_index in index_output:\n",
    "    train_data = transactions.loc[train_index]\n",
    "    val_data = transactions.loc[val_index]\n",
    "    # 取得val開始日期\n",
    "    val_data.reset_index(inplace=True, drop=True)\n",
    "    start_val = val_data['t_dat'][0]\n",
    "    # 呼叫訓練模型的function\n",
    "    one_fold_scores = model.train_ALS(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "    scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "# average_r2score = np.mean(scores)\n",
    "\n",
    "scores.to_parquet('model/params/params_stride30/implicit_ALS_train180.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做 time based split 270天\n",
    "train_period, val_period, stride = 270, 7, 30\n",
    "index_output = tscv.split(transactions, date_column='t_dat', train_period=train_period, val_period=val_period, stride=stride,show_progress=True)\n",
    "\n",
    "# 做 time based CV\n",
    "scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "for train_index, val_index in index_output:\n",
    "    train_data = transactions.loc[train_index]\n",
    "    val_data = transactions.loc[val_index]\n",
    "    # 取得val開始日期\n",
    "    val_data.reset_index(inplace=True, drop=True)\n",
    "    start_val = val_data['t_dat'][0]\n",
    "    # 呼叫訓練模型的function\n",
    "    one_fold_scores = model.train_ALS(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "    scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "# average_r2score = np.mean(scores)\n",
    "\n",
    "scores.to_parquet('model/params/params_stride30/implicit_ALS_train270.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做 time based split 360天\n",
    "train_period, val_period, stride = 360, 7, 30\n",
    "index_output = tscv.split(transactions, date_column='t_dat', train_period=train_period, val_period=val_period, stride=stride,show_progress=True)\n",
    "\n",
    "# 做 time based CV\n",
    "scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "for train_index, val_index in index_output:\n",
    "    train_data = transactions.loc[train_index]\n",
    "    val_data = transactions.loc[val_index]\n",
    "    # 取得val開始日期\n",
    "    val_data.reset_index(inplace=True, drop=True)\n",
    "    start_val = val_data['t_dat'][0]\n",
    "    # 呼叫訓練模型的function\n",
    "    one_fold_scores = model.train_ALS(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "    scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "# average_r2score = np.mean(scores)\n",
    "\n",
    "scores.to_parquet('model/params/params_stride30/implicit_ALS_train360.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合併所有dataframe\n",
    "periods = [30,60,90,180,270,360]\n",
    "total_scores = pd.DataFrame()\n",
    "\n",
    "for period in periods:\n",
    "    perios_socres = pd.read_parquet(f\"model/params/params_stride30/implicit_ALS_train{period}.parquet\")\n",
    "    total_scores = pd.concat([total_scores,perios_socres],axis=0,ignore_index=True)\n",
    "    \n",
    "total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看最佳的參數組合\n",
    "total_scores.groupby(['train_period','factors','iterations','regularization']).mean('map12').sort_values('map12',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 彙整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import *\n",
    "from model.TimeBasedCV import TimeBasedCV\n",
    "\n",
    "transactions = pd.read_parquet('data\\\\HM_parquet\\\\transactions_train.parquet')\n",
    "customers = pd.read_parquet('data\\\\HM_parquet\\\\customers.parquet')\n",
    "articles = pd.read_parquet('data\\\\HM_parquet\\\\articles.parquet')\n",
    "\n",
    "tscv = TimeBasedCV(freq='days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 測試將函數傳入函數\n",
    "def test(model,train_data,val_data,train_period,stride):\n",
    "    val_period = 7\n",
    "    scores_one_month = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "    one_fold_scores = model(train_data, val_data, train_period, val_period, stride,start_val=0)\n",
    "    scores_one_month = pd.concat([scores_one_month,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "    return scores_one_month\n",
    "\n",
    "model = als()\n",
    "\n",
    "# 測試一個月的資料\n",
    "# transactions = pd.read_parquet('data\\\\HM_parquet\\\\transactions_train.parquet')\n",
    "train_one_month = pd.read_parquet('data/train_one_month.parquet')\n",
    "val_one_parquet = pd.read_parquet('data/val_one_month.parquet')\n",
    "\n",
    "train_one_month = model.data_preprocess(train_one_month,customers,articles)\n",
    "val_one_parquet = model.data_preprocess(val_one_parquet,customers,articles)\n",
    "\n",
    "scores_one_month = test(model.train_ALS,train_one_month,val_one_parquet,30,30)\n",
    "scores_one_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_base_model(model,data,date_column,train_period,stride):\n",
    "    # time based split\n",
    "    val_period=7\n",
    "    index_output = tscv.split(data, date_column, train_period, val_period, stride, show_progress=False)\n",
    "\n",
    "    # 做 time based CV\n",
    "    scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "    for train_index, val_index in index_output:\n",
    "        train_data = transactions.loc[train_index]\n",
    "        val_data = transactions.loc[val_index]\n",
    "        # 取得val開始日期\n",
    "        val_data.reset_index(inplace=True, drop=True)\n",
    "        start_val = val_data[date_column][0]\n",
    "        # 呼叫訓練模型的function\n",
    "        one_fold_scores = model(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "        scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用迴圈跑不同時間段\n",
    "from model.ImplicitALS import ImplicitALS as als\n",
    "\n",
    "model = als()\n",
    "\n",
    "data = model.data_preprocess(transactions,customers,articles)\n",
    "date_column='t_dat'\n",
    "train_periods = [30,60,90,180,270,360]\n",
    "stride = 30\n",
    "\n",
    "# 做 time based split\n",
    "for train_period in train_periods:\n",
    "    one_period_scores = time_base_model(model,transactions,date_column,train_period,stride)\n",
    "    one_period_scores.to_parquet(f'model/params/params_stride30/implicit_ALS_train{train_period}.parquet')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "666666666"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a92cbcf0e54319bd537504dd06c788c2290917353461c754c87e8cf50a6053b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
