{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surprise.SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGdzFLT5huQb",
    "outputId": "2ec1b0f6-f228-4934-ded5-d15235d28f98"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp,SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import ml_metrics as metrics\n",
    "\n",
    "class surpriseSVD():\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "\n",
    "    def get_top_n(self, predictions, n=12):\n",
    "        \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "        Args:\n",
    "            predictions(list of Prediction objects): The list of predictions, as\n",
    "                returned by the test method of an algorithm.\n",
    "            n(int): The number of recommendation to output for each user. Default\n",
    "                is 10.\n",
    "        Returns:\n",
    "        A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "            [(raw item id, rating estimation), ...] of size n.\n",
    "        \"\"\"\n",
    "\n",
    "        # First map the predictions to each user.\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "\n",
    "        # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "\n",
    "        return top_n\n",
    "\n",
    "    def get_set(self,df):\n",
    "        reader = Reader(rating_scale=(1, 500))\n",
    "        data_set = Dataset.load_from_df(df[['customer_id','article_id','rating']], reader)\n",
    "        return data_set\n",
    "\n",
    "    def get_rating_set(self,df):\n",
    "        rating = df[['customer_id','article_id','price']].groupby(['customer_id','article_id']).count().reset_index()\n",
    "        rating.columns = ['customer_id','article_id','rating']\n",
    "        rating_set = self.get_set(rating)\n",
    "        return rating_set\n",
    "\n",
    "\n",
    "    def train_SVD(self, train_data, test_data, train_period, val_period, stride, start_val):\n",
    "\n",
    "        ## 讀取評分資料為surprise可以訓練的格式\n",
    "        trainset = self.get_rating_set(train_data)\n",
    "        testset = self.get_rating_set(test_data)\n",
    "\n",
    "        ## rmse 需要的資料\n",
    "        testset2 = [testset.df.loc[i].to_list() for i in range(len(testset.df))]\n",
    "\n",
    "        ## map@k testing 需要產的資料\n",
    "        test_data.loc[:,'rating']=0\n",
    "        test_processed = self.get_set(test_data)\n",
    "        NA, test2 = train_test_split(test_processed, test_size=1.0)\n",
    "\n",
    "        # ======= 消費者的實際購買清單 =======\n",
    "        test_data['article_id'] = test_data['article_id'].astype('str')\n",
    "        test_uni = test_data.drop_duplicates(subset=['customer_id', 'article_id'], keep='first')\n",
    "        buy_n = test_uni[['customer_id','article_id']].groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "        cust_actual_list = []\n",
    "        for uid, user_ratings in buy_n.items():\n",
    "            cust_pred_tuple = (uid, [iid for iid in user_ratings])\n",
    "            cust_actual_list.append(cust_pred_tuple)\n",
    "\n",
    "        # ======= 訓練 SVD 模型 =======\n",
    "        scores = pd.DataFrame()\n",
    "        for factors in [25,50,100,150,200]:\n",
    "            for iterations in [20,30,40,50]:\n",
    "        # for factors in [25]:\n",
    "        #     for iterations in [20]:\n",
    "                for regularization in [0.01]:\n",
    "\n",
    "                    algo = SVD(n_factors = factors,\n",
    "                            n_epochs=iterations,\n",
    "                            reg_all=regularization,\n",
    "                            random_state=42)\n",
    "\n",
    "                    # 訓練模型\n",
    "                    algo.fit(trainset.build_full_trainset())\n",
    "                    # step3 - testing(train_test_split way)\n",
    "                    \n",
    "                    ##### rmse #####\n",
    "                    predictions = algo.test(testset2)\n",
    "                    rmse = accuracy.rmse(predictions)\n",
    "\n",
    "                    ##### map@k #####\n",
    "                    predictions_map = algo.test(test2)\n",
    "                    # est = [i.est for i in predictions_map] \n",
    "\n",
    "                    ##  消費者的預測清單 \n",
    "                    top_n = self.get_top_n(predictions=predictions_map, n=12)\n",
    "\n",
    "                    cust_pred_list = []\n",
    "                    for uid, user_ratings in top_n.items():\n",
    "                        cust_pred_tuple = (uid, [str(iid) for (iid, _) in user_ratings])\n",
    "                        cust_pred_list.append(cust_pred_tuple)\n",
    "\n",
    "                    final_list = list(zip(cust_actual_list, cust_pred_list))\n",
    "\n",
    "                    # map@k計算 \n",
    "                    mapk_list = []\n",
    "                    for i in range(len(final_list)):\n",
    "                        map_k = metrics.mapk([final_list[i][0][1]],[final_list[i][1][1]],12)\n",
    "                        mapk_list.append(map_k)\n",
    "\n",
    "                        # def Average(lst):\n",
    "                        #     return sum(lst) / len(lst)\n",
    "\n",
    "                        # map_k = Average(mapk_list)\n",
    "\n",
    "                    map_k = sum(mapk_list)/len(mapk_list)\n",
    "\n",
    "                    newRow = {\n",
    "                            'train_period':train_period, \n",
    "                            'val_period':val_period, \n",
    "                            'stride':stride, \n",
    "                            'start_val':start_val,\n",
    "                            # =====填寫參數名稱===============\n",
    "                            'factors':factors, \n",
    "                            'iterations':iterations, \n",
    "                            'regularization':regularization, \n",
    "                            # ===============================\n",
    "                            'rmse':rmse,\n",
    "                            'map@k':map_k\n",
    "                            }\n",
    "                    newDF = pd.DataFrame([newRow])\n",
    "                    scores = pd.concat([scores, newDF], axis=0 ,ignore_index=True)\n",
    "                    print(newRow)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試一個月的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試一個月的資料\n",
    "train_data = pd.read_parquet('../data/HM_parquet/train_one_month.parquet')\n",
    "test_data = pd.read_parquet('../data/HM_parquet/val_one_month.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4548\n",
      "{'train_period': 30, 'val_period': 7, 'stride': 30, 'start_val': 0, 'factors': 25, 'iterations': 20, 'regularization': 0.01, 'rmse': 0.4548226270871537, 'map@k': 0.0007275515180981462}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_period, val_period, stride = 30, 7, 30\n",
    "start_val = 0\n",
    "scores_one_month = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "model = surpriseSVD()\n",
    "one_fold_scores = model.train_SVD(train_data, test_data, train_period, val_period, stride,start_val=0)\n",
    "# scores_one_month = pd.concat([scores_one_month,one_fold_scores], axis=0 ,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_period</th>\n",
       "      <th>val_period</th>\n",
       "      <th>stride</th>\n",
       "      <th>start_val</th>\n",
       "      <th>factors</th>\n",
       "      <th>iterations</th>\n",
       "      <th>regularization</th>\n",
       "      <th>rmse</th>\n",
       "      <th>map@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.454823</td>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_period  val_period  stride  start_val  factors  iterations  \\\n",
       "0            30           7      30          0       25          20   \n",
       "\n",
       "   regularization      rmse     map@k  \n",
       "0            0.01  0.454823  0.000728  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_fold_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分別取不同時間段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import *\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from surpriseSVD import surpriseSVD as svd\n",
    "\n",
    "model = svd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet('../data/HM_parquet/transactions_train.parquet')\n",
    "customers = pd.read_parquet('../data/HM_parquet/customers.parquet')\n",
    "articles = pd.read_parquet('../data/HM_parquet/articles.parquet')\n",
    "\n",
    "tscv = TimeBasedCV(freq='days')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split_model(train_period):\n",
    "    # 做 time based split\n",
    "    test_period, stride = 7, 30\n",
    "    index_output = tscv.split(transactions, date_column='t_dat', train_period=train_period, test_period=test_period, stride=stride,show_progress=False)\n",
    "\n",
    "    # 做 time based CV\n",
    "    scores = pd.DataFrame(columns=[\"train_period\",\"val_period\",\"stride\"])\n",
    "\n",
    "    for train_index, val_index in index_output:\n",
    "        train_data = transactions.loc[train_index]\n",
    "        val_data = transactions.loc[val_index]\n",
    "        # 取得val開始日期\n",
    "        val_data.reset_index(inplace=True, drop=True)\n",
    "        start_val = val_data['t_dat'][0]\n",
    "        # 呼叫訓練模型的function\n",
    "        one_fold_scores = model.train_SVD(train_data, val_data, train_period, val_period, stride, start_val)\n",
    "        scores = pd.concat([scores,one_fold_scores], axis=0 ,ignore_index=True)\n",
    "\n",
    "    scores.to_parquet(f'model/params/params_SVD_stride30/surprise_SVD_train{train_period}.parquet')\n",
    "    print(f\"完成存檔: surprise_SVD_train{train_period}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_model(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_model(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_model(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_model(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_model(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_model(360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合併所有dataframe\n",
    "periods = [30,60,90,180,270,360]\n",
    "total_scores = pd.DataFrame()\n",
    "\n",
    "for period in periods:\n",
    "    perios_socres = pd.read_parquet(f'model/params/params_SVD_stride30/surprise_SVD_train{period}.parquet')\n",
    "    total_scores = pd.concat([total_scores,perios_socres],axis=0,ignore_index=True)\n",
    "    \n",
    "total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看最佳的參數組合\n",
    "total_scores.groupby(['train_period','factors','iterations','regularization']).mean('map12').sort_values('map12',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a92cbcf0e54319bd537504dd06c788c2290917353461c754c87e8cf50a6053b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
