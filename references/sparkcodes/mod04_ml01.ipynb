{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local mode\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"lr\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yarn mode\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config('spark.executor.instances','99')\\\n",
    "        .config('spark.executor.memory','4G')\\\n",
    "        .appName(\"iris\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PySparkShell'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check spark app name\n",
    "spark.sparkContext.appName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.set_option(\"compute.default_index_type\", \"distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print runtime versions\n",
    "# Python version\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark version\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris.csv into Spark dataframe\n",
    "#df = spark.read.csv('file:///vagrant/data/lr_dataset.csv', header=True, inferSchema=True)\n",
    "psdf = ps.read_csv('data/lr_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the size of data\n",
    "psdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_1  var_2  var_3  var_4  var_5  output\n",
       "0    734    688     81  0.328  0.259   0.418\n",
       "1    700    600     94  0.320  0.247   0.389\n",
       "2    712    705     93  0.311  0.247   0.417\n",
       "3    734    806     69  0.315  0.260   0.415\n",
       "4    613    759     61  0.302  0.240   0.378"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 rows of Iris dataset\n",
    "psdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_1       int32\n",
       "var_2       int32\n",
       "var_3       int32\n",
       "var_4     float64\n",
       "var_5     float64\n",
       "output    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>715.081981</td>\n",
       "      <td>715.081981</td>\n",
       "      <td>80.904221</td>\n",
       "      <td>0.326331</td>\n",
       "      <td>0.259273</td>\n",
       "      <td>0.397342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>91.534294</td>\n",
       "      <td>93.079933</td>\n",
       "      <td>11.458139</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>0.012907</td>\n",
       "      <td>0.033267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>463.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>711.000000</td>\n",
       "      <td>709.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>775.000000</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0.337000</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1009.000000</td>\n",
       "      <td>1103.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.373000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.491000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             var_1        var_2        var_3        var_4        var_5       output\n",
       "count  1232.000000  1232.000000  1232.000000  1232.000000  1232.000000  1232.000000\n",
       "mean    715.081981   715.081981    80.904221     0.326331     0.259273     0.397342\n",
       "std      91.534294    93.079933    11.458139     0.015013     0.012907     0.033267\n",
       "min     463.000000   472.000000    40.000000     0.277000     0.214000     0.301000\n",
       "25%     652.000000   649.000000    73.000000     0.317000     0.251000     0.375000\n",
       "50%     711.000000   709.000000    81.000000     0.326000     0.260000     0.396000\n",
       "75%     775.000000   774.000000    89.000000     0.337000     0.268000     0.421000\n",
       "max    1009.000000  1103.000000   116.000000     0.373000     0.294000     0.491000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:87: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  Unsupported type in conversion to Arrow: MatrixUDT\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380139</td>\n",
       "      <td>0.511745</td>\n",
       "      <td>0.900492</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>0.918740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_2</th>\n",
       "      <td>0.380139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.532394</td>\n",
       "      <td>0.326360</td>\n",
       "      <td>0.330764</td>\n",
       "      <td>0.436527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_3</th>\n",
       "      <td>0.511745</td>\n",
       "      <td>-0.532394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.408716</td>\n",
       "      <td>0.401496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_4</th>\n",
       "      <td>0.900492</td>\n",
       "      <td>0.326360</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851958</td>\n",
       "      <td>0.790910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_5</th>\n",
       "      <td>0.827000</td>\n",
       "      <td>0.330764</td>\n",
       "      <td>0.408716</td>\n",
       "      <td>0.851958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>0.918740</td>\n",
       "      <td>0.436527</td>\n",
       "      <td>0.401496</td>\n",
       "      <td>0.790910</td>\n",
       "      <td>0.790481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           var_1     var_2     var_3     var_4     var_5    output\n",
       "var_1   1.000000  0.380139  0.511745  0.900492  0.827000  0.918740\n",
       "var_2   0.380139  1.000000 -0.532394  0.326360  0.330764  0.436527\n",
       "var_3   0.511745 -0.532394  1.000000  0.481836  0.408716  0.401496\n",
       "var_4   0.900492  0.326360  0.481836  1.000000  0.851958  0.790910\n",
       "var_5   0.827000  0.330764  0.408716  0.851958  1.000000  0.790481\n",
       "output  0.918740  0.436527  0.401496  0.790910  0.790481  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.corr()\n",
    "# check for correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = psdf.to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|corr(var_1, output)|\n",
      "+-------------------+\n",
      "| 0.9187399607627283|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for correlation\n",
    "df.select(fn.corr('var_1','output')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'output']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize all numerical columns into a single feature column\n",
    "feature_cols = df.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "features_df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# validate the presence of dense vectors \n",
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|features                      |\n",
      "+------------------------------+\n",
      "|[734.0,688.0,81.0,0.328,0.259]|\n",
      "|[700.0,600.0,94.0,0.32,0.247] |\n",
      "|[712.0,705.0,93.0,0.311,0.247]|\n",
      "|[734.0,806.0,69.0,0.315,0.26] |\n",
      "|[613.0,759.0,61.0,0.302,0.24] |\n",
      "+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the details of dense vector\n",
    "features_df.select('features').show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select the features and label column\n",
    "model_df = features_df.select(['features', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+\n",
      "|features                      |output|\n",
      "+------------------------------+------+\n",
      "|[734.0,688.0,81.0,0.328,0.259]|0.418 |\n",
      "|[700.0,600.0,94.0,0.32,0.247] |0.389 |\n",
      "|[712.0,705.0,93.0,0.311,0.247]|0.417 |\n",
      "|[734.0,806.0,69.0,0.315,0.26] |0.415 |\n",
      "|[613.0,759.0,61.0,0.302,0.24] |0.378 |\n",
      "|[748.0,676.0,85.0,0.318,0.255]|0.422 |\n",
      "|[669.0,588.0,97.0,0.315,0.251]|0.411 |\n",
      "|[667.0,845.0,68.0,0.324,0.251]|0.381 |\n",
      "|[758.0,890.0,64.0,0.33,0.274] |0.436 |\n",
      "|[726.0,670.0,88.0,0.335,0.268]|0.422 |\n",
      "+------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading for machine learning\n",
    "model_df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of model df\n",
    "model_df.count(), len(model_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data - Train & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Logistic Regression to train on the training set\n",
    "train_df, test_df = model_df.randomSplit([0.70, 0.30], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(), len(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count(), len(test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Linear Regression model \n",
    "lin_Reg=LinearRegression(labelCol='output', regParam=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the linear regression model on training data set \n",
    "lr_model=lin_Reg.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011465069326171773"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0001, 0.0001, 0.0004, 0.2526, 0.4707])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions=lr_model.evaluate(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00019144601401315477"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_predictions.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8216224494227173"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_predictions.r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data \n",
    "test_results=lr_model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|residuals             |\n",
      "+----------------------+\n",
      "|0.002382055197662103  |\n",
      "|-0.014547863851062492 |\n",
      "|-0.012039623917925624 |\n",
      "|-0.011109420628882039 |\n",
      "|-0.002616531852948356 |\n",
      "|-0.009854073751058456 |\n",
      "|-0.008927654496298232 |\n",
      "|-2.0828312883258704E-4|\n",
      "|-0.013569479790375094 |\n",
      "|-0.001270181110074986 |\n",
      "+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# view the residual errors based on predictions \n",
    "test_results.residuals.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8143179975922307"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficient of determination value for model\n",
    "test_results.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014908637721399215"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "test_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002222674787079276"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "test_results.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
