{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14dae610-abeb-4153-9779-c8ec43fc57a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bdse111.example.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>maggie</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa0290b6700>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05254aa8-95e6-40f0-a5e8-efc8a62bb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import (\n",
    "    DoubleType, FloatType, IntegerType, StringType, StructField, StructType\n",
    ")\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c56adc-9f00-4650-818e-ae34eff7feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 20\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d8f776-77d5-4188-80c7-8365af6e6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test, kwargs={}):\n",
    "\n",
    "    # split data\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # create model\n",
    "    model = CatBoostClassifier(\n",
    "        nan_mode='Min',\n",
    "        random_seed=42,\n",
    "        boosting_type='Plain',\n",
    "        bootstrap_type='Bernoulli',\n",
    "        rsm=0.1,\n",
    "        loss_function='Logloss',\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=100,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train.values, y_train.values, eval_set=(X_eval, y_eval))\n",
    "    \n",
    "    # evaluate model\n",
    "    accuracy = accuracy_score(model.predict(X_test), y_test)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2fe47-c209-4bb9-8e7b-9a26d934a593",
   "metadata": {},
   "source": [
    "# 產生data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c6b8ce-9dab-411f-a007-0c7539e8abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=N_FEATURES,\n",
    "    n_classes=N_CLASSES,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d60dacd-efdc-4a22-82b5-867eefa4b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(X)\n",
    "for i in range(N_CLASSES):\n",
    "    pdf[f'y_{i}'] = y[:, i]\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c475daf2-f9ac-4a48-adab-f0da61fe4167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 15:57:45,753 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 0:===================================================>     (20 + 2) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in the dataset: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'number of rows in the dataset: {df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7b11eb-54da-426b-bec4-db9e7a5850cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+----+----+---+---+---+---+---+---+---+---+---+---+\n",
      "|  0|  1|  2|  3|  4|  5|  6|  7|  8|  9| 10| 11|  12| 13| 14| 15| 16| 17|  18|  19|y_0|y_1|y_2|y_3|y_4|y_5|y_6|y_7|y_8|y_9|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+----+----+---+---+---+---+---+---+---+---+---+---+\n",
      "|2.0|2.0|0.0|1.0|3.0|5.0|0.0|3.0|4.0|1.0|2.0|5.0| 2.0|1.0|4.0|1.0|3.0|4.0|10.0| 2.0|  0|  1|  1|  0|  0|  0|  0|  1|  0|  0|\n",
      "|4.0|3.0|2.0|2.0|0.0|4.0|1.0|2.0|0.0|3.0|1.0|7.0| 4.0|2.0|3.0|1.0|2.0|2.0| 2.0| 1.0|  0|  0|  0|  0|  0|  0|  0|  1|  1|  1|\n",
      "|2.0|2.0|3.0|0.0|0.0|0.0|0.0|6.0|0.0|3.0|4.0|0.0| 5.0|1.0|0.0|0.0|1.0|2.0| 4.0| 0.0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|0.0|1.0|4.0|4.0|2.0|0.0|2.0|1.0|3.0|2.0|1.0|1.0| 3.0|0.0|0.0|2.0|6.0|3.0| 3.0| 1.0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|0.0|0.0|7.0|2.0|1.0|0.0|1.0|2.0|1.0|2.0|2.0|1.0| 4.0|0.0|5.0|5.0|0.0|0.0| 4.0| 2.0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|\n",
      "|5.0|2.0|0.0|1.0|2.0|3.0|1.0|3.0|1.0|3.0|2.0|4.0| 4.0|2.0|2.0|0.0|3.0|2.0| 5.0|10.0|  1|  1|  0|  1|  0|  0|  0|  1|  0|  0|\n",
      "|3.0|1.0|0.0|0.0|5.0|4.0|0.0|2.0|6.0|3.0|7.0|2.0| 0.0|4.0|2.0|1.0|4.0|6.0| 6.0| 2.0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|\n",
      "|5.0|2.0|1.0|4.0|3.0|3.0|0.0|3.0|0.0|7.0|2.0|2.0| 1.0|2.0|2.0|2.0|0.0|0.0| 4.0| 0.0|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|\n",
      "|2.0|2.0|1.0|1.0|5.0|5.0|0.0|0.0|4.0|1.0|4.0|3.0| 1.0|2.0|1.0|1.0|2.0|2.0| 5.0| 1.0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|\n",
      "|1.0|2.0|2.0|5.0|3.0|3.0|3.0|1.0|3.0|3.0|4.0|2.0| 1.0|0.0|2.0|3.0|1.0|6.0| 3.0| 2.0|  0|  0|  1|  1|  0|  0|  0|  0|  0|  0|\n",
      "|1.0|1.0|3.0|5.0|3.0|3.0|1.0|2.0|1.0|0.0|4.0|6.0| 5.0|1.0|4.0|5.0|1.0|4.0| 3.0| 0.0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  1|\n",
      "|4.0|3.0|2.0|5.0|3.0|0.0|0.0|7.0|3.0|4.0|5.0|3.0| 2.0|0.0|2.0|2.0|0.0|1.0| 5.0| 1.0|  0|  1|  0|  0|  1|  0|  0|  0|  1|  1|\n",
      "|4.0|2.0|1.0|2.0|1.0|7.0|1.0|3.0|1.0|5.0|0.0|1.0| 3.0|3.0|4.0|0.0|1.0|3.0| 5.0| 1.0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|\n",
      "|5.0|2.0|3.0|3.0|6.0|4.0|2.0|1.0|2.0|2.0|8.0|1.0| 2.0|0.0|1.0|3.0|2.0|4.0| 2.0| 0.0|  0|  0|  1|  0|  0|  1|  0|  0|  0|  0|\n",
      "|0.0|1.0|3.0|0.0|3.0|2.0|5.0|4.0|2.0|3.0|1.0|6.0| 1.0|1.0|4.0|4.0|5.0|5.0| 4.0| 1.0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|3.0|3.0|5.0|1.0|2.0|3.0|3.0|3.0|2.0|1.0|4.0|4.0| 1.0|0.0|4.0|2.0|0.0|3.0| 4.0| 3.0|  0|  0|  0|  1|  0|  1|  0|  0|  0|  1|\n",
      "|0.0|4.0|7.0|1.0|4.0|2.0|0.0|1.0|6.0|3.0|3.0|1.0| 2.0|2.0|4.0|0.0|4.0|2.0| 1.0| 1.0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|2.0|3.0|1.0|2.0|3.0|3.0|3.0|4.0|2.0|3.0|3.0|1.0|10.0|2.0|0.0|3.0|3.0|3.0| 3.0| 0.0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|2.0|3.0|3.0|5.0|1.0|2.0|3.0|0.0|2.0|2.0|2.0|3.0| 2.0|2.0|4.0|1.0|3.0|3.0| 2.0| 2.0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|3.0|1.0|3.0|5.0|1.0|1.0|2.0|1.0|3.0|1.0|6.0|1.0| 0.0|1.0|2.0|2.0|1.0|2.0| 5.0| 0.0|  0|  1|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+----+----+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看數據\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8977ff8b-2e99-4c22-9ddf-ceeb17910c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.execution.arrow.pyspark.enabled\")  # Keep its default value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f8c58-bf59-49f4-99a2-eb1cef54442d",
   "metadata": {},
   "source": [
    "# Distributed Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc7222b2-4d28-4d1a-8728-efd1b212b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_range = list(\n",
    "    product(\n",
    "        [200, 250],\n",
    "        [3, 5, 7],\n",
    "        [0.02, 0.1, 0.2],\n",
    "        ['MinEntropy', 'Uniform', 'UniformAndQuantiles', 'GreedyLogSum'],\n",
    "        [1.0],\n",
    "        [0.5],\n",
    "    )\n",
    ")\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('iterations', IntegerType(), True),\n",
    "        StructField('depth', IntegerType(), True),\n",
    "        StructField('learning_rate', DoubleType(), True),\n",
    "        StructField('feature_border_type', StringType(), True),\n",
    "        StructField('l2_leaf_reg', FloatType(), True),\n",
    "        StructField('subsample', FloatType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_grid = spark.createDataFrame(data=values_range, schema=schema)\n",
    "df_grid = df_grid.withColumn('replication_id', sf.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3baafdd-8e71-4dfb-a2f6-e55943335674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------------+-------------------+-----------+---------+--------------+\n",
      "|iterations|depth|learning_rate|feature_border_type|l2_leaf_reg|subsample|replication_id|\n",
      "+----------+-----+-------------+-------------------+-----------+---------+--------------+\n",
      "|       200|    3|         0.02|         MinEntropy|        1.0|      0.5|             0|\n",
      "|       200|    3|         0.02|            Uniform|        1.0|      0.5|             1|\n",
      "|       200|    3|         0.02|UniformAndQuantiles|        1.0|      0.5|             2|\n",
      "|       200|    3|         0.02|       GreedyLogSum|        1.0|      0.5|    8589934592|\n",
      "|       200|    3|          0.1|         MinEntropy|        1.0|      0.5|    8589934593|\n",
      "|       200|    3|          0.1|            Uniform|        1.0|      0.5|    8589934594|\n",
      "|       200|    3|          0.1|UniformAndQuantiles|        1.0|      0.5|   17179869184|\n",
      "|       200|    3|          0.1|       GreedyLogSum|        1.0|      0.5|   17179869185|\n",
      "|       200|    3|          0.2|         MinEntropy|        1.0|      0.5|   17179869186|\n",
      "|       200|    3|          0.2|            Uniform|        1.0|      0.5|   25769803776|\n",
      "|       200|    3|          0.2|UniformAndQuantiles|        1.0|      0.5|   25769803777|\n",
      "|       200|    3|          0.2|       GreedyLogSum|        1.0|      0.5|   25769803778|\n",
      "|       200|    5|         0.02|         MinEntropy|        1.0|      0.5|   34359738368|\n",
      "|       200|    5|         0.02|            Uniform|        1.0|      0.5|   34359738369|\n",
      "|       200|    5|         0.02|UniformAndQuantiles|        1.0|      0.5|   34359738370|\n",
      "|       200|    5|         0.02|       GreedyLogSum|        1.0|      0.5|   42949672960|\n",
      "|       200|    5|          0.1|         MinEntropy|        1.0|      0.5|   42949672961|\n",
      "|       200|    5|          0.1|            Uniform|        1.0|      0.5|   42949672962|\n",
      "|       200|    5|          0.1|UniformAndQuantiles|        1.0|      0.5|   51539607552|\n",
      "|       200|    5|          0.1|       GreedyLogSum|        1.0|      0.5|   51539607553|\n",
      "+----------+-----+-------------+-------------------+-----------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grid.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "298ee751-a1be-4986-9e15-8b8615e6140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different hyperparameter combinations: 72\n"
     ]
    }
   ],
   "source": [
    "print(f'number of different hyperparameter combinations: {df_grid.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "001e82c5-cacb-424e-9429-9cdae6172618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 data 和 參數表 結合\n",
    "df_replicated = df.crossJoin(df_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2190f4ee-ce17-489e-ac5b-746025f03226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:===============================================>     (434 + 23) / 484]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in the replicated dataset: 72000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'number of rows in the replicated dataset: {df_replicated.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efe044-9731-4700-ad96-8af38d950490",
   "metadata": {},
   "source": [
    "# Pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51eff0de-eb03-41e5-8270-7afb5389d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the schema for the output of our function\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('replication_id', IntegerType(),True),\n",
    "        StructField('accuracy', FloatType(),True),\n",
    "        StructField(\"iterations\", IntegerType(), True),\n",
    "        StructField(\"depth\", IntegerType(), True),\n",
    "        StructField(\"learning_rate\", DoubleType(), True),\n",
    "        StructField(\"feature_border_type\", StringType(), True),\n",
    "        StructField(\"l2_leaf_reg\", FloatType(), True),\n",
    "        StructField(\"subsample\", FloatType(), True)\n",
    "     ]\n",
    ")\n",
    "\n",
    "# decorate our function with pandas_udf decorator\n",
    "# @pandas_udf(schema, sf.PandasUDFType.GROUPED_MAP)\n",
    "def hyperparameter_search(pdf):\n",
    "\n",
    "    # get hyperparameter values\n",
    "    kwargs = {\n",
    "        'iterations': pdf.iterations.values[0],\n",
    "        'depth': pdf.depth.values[0],\n",
    "        'learning_rate': pdf.learning_rate.values[0],\n",
    "        'feature_border_type': pdf.feature_border_type.values[0],\n",
    "        'l2_leaf_reg': pdf.l2_leaf_reg.values[0],\n",
    "        'subsample': pdf.subsample.values[0]\n",
    "    }\n",
    "    \n",
    "    # get data and label\n",
    "    X = pdf[[str(i) for i in range(N_FEATURES)]]\n",
    "    y = pdf['y_0']\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # get accuracy\n",
    "    accuracy = train_and_evaluate_model(X_train, y_train, X_test, y_test, kwargs)\n",
    "\n",
    "    # return results as pandas DF\n",
    "    kwargs.update({\n",
    "        'replication_id': pdf.replication_id.values[0],\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "    results = pd.DataFrame([kwargs])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "870067ac-4926-4ea1-852e-d48a88706fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df_replicated.groupby('replication_id').applyInPandas(hyperparameter_search,schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd10d6ab-35e4-418b-9925-b453249e98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = results.sort('accuracy', ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2e0637d-9bbf-43e2-96ee-855182418714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+----------+-----+-------------+-------------------+-----------+---------+\n",
      "|replication_id|accuracy|iterations|depth|learning_rate|feature_border_type|l2_leaf_reg|subsample|\n",
      "+--------------+--------+----------+-----+-------------+-------------------+-----------+---------+\n",
      "|             2|   0.915|       250|    7|          0.1|            Uniform|        1.0|      0.5|\n",
      "|             2|    0.91|       200|    7|          0.1|            Uniform|        1.0|      0.5|\n",
      "|             1|    0.91|       250|    3|          0.2|UniformAndQuantiles|        1.0|      0.5|\n",
      "|             0|     0.9|       250|    3|          0.1|UniformAndQuantiles|        1.0|      0.5|\n",
      "|             1|     0.9|       250|    3|          0.1|         MinEntropy|        1.0|      0.5|\n",
      "+--------------+--------+----------+-----+-------------+-------------------+-----------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf489fa5-f2c2-447f-9767-3c496a9adfed",
   "metadata": {},
   "source": [
    "# Distributed K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1426f49-bbed-4631-bd27-b43a692ddcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b01eebb7-31d8-48d6-a18c-36c94b00db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 1 / N_FOLDS\n",
    "splits = df.randomSplit([proportion] * N_FOLDS, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e340b1d-1ad3-4e91-8dbf-bcb57d33aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_folds = splits[0].withColumn('fold', sf.lit(0))\n",
    "for i in range(1, N_FOLDS):\n",
    "    df_folds = df_folds.union(\n",
    "        splits[i].withColumn('fold', sf.lit(i))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f55ee177-a340-4cf2-9edd-716f0da53862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6a83c-c024-4fcd-9696-650a4868a26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c83e29e-7989-485a-ae06-f959da074eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers = spark.createDataFrame(\n",
    "    pd.DataFrame(list(range(N_FOLDS)),columns=['replication_id'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af82f4d1-49f1-41f2-aa88-cd7a32b96364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replication_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   replication_id\n",
       "0               0\n",
       "1               1\n",
       "2               2\n",
       "3               3\n",
       "4               4\n",
       "5               5\n",
       "6               6\n",
       "7               7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numbers.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acd9a9a2-5fa8-4ab8-8491-feb649d1d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replicated = df_folds.crossJoin(df_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f32730e9-08fe-4b14-84b6-7d058aa1cef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:==================================================>(1551 + 14) / 1568]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in the replicated dataset: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'number of rows in the replicated dataset: {df_replicated.count()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e442a3c-ac62-401e-be1d-8986d4bec1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the schema for the output of our function\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('replication_id', IntegerType(), True),\n",
    "        StructField('accuracy', FloatType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# decorate our function with pandas_udf decorator\n",
    "@pandas_udf(schema, sf.PandasUDFType.GROUPED_MAP)\n",
    "def cross_validation(pdf):\n",
    "    \n",
    "    # get repliaction id\n",
    "    replication_id = pdf.replication_id.values[0]\n",
    "    \n",
    "    # get data and label\n",
    "    columns = [str(i) for i in range(N_FEATURES)]\n",
    "    X_train = pdf[pdf.fold != replication_id][columns]\n",
    "    X_test = pdf[pdf.fold == replication_id][columns]\n",
    "    y_train = pdf[pdf.fold != replication_id]['y_0']\n",
    "    y_test = pdf[pdf.fold == replication_id]['y_0']\n",
    "\n",
    "    # get accuracy\n",
    "    accuracy = train_and_evaluate_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # return results as pandas DF\n",
    "    results = pd.DataFrame([{\n",
    "        'replication_id': replication_id,\n",
    "        'accuracy': accuracy\n",
    "    }])\n",
    "\n",
    "    # save the model (if you want to retrieve it later)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cc07640-f8ee-44e7-bb40-4e6479e2ec5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/group_ops.py:81: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = df_replicated.groupby('replication_id').apply(cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39e4b472-32e1-4d99-acfc-fa1343cfc363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results8 = results.sort('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0b6e1f7-9f46-49e0-9ab5-b957a4348fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results8.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2595d50a-f7b6-478a-840b-49494d3b8c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|replication_id|  accuracy|\n",
      "+--------------+----------+\n",
      "|             2| 0.9310345|\n",
      "|             6| 0.8939394|\n",
      "|             1| 0.8914729|\n",
      "|             3|0.88429755|\n",
      "|             5| 0.8602941|\n",
      "|             7| 0.8429752|\n",
      "|             4|0.84166664|\n",
      "|             0|     0.824|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20685b04-3e24-4e9c-bb3f-bbe749ddd785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
