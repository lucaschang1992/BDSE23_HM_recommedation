{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local mode\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"iris\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yarn mode\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config('spark.executor.instances','99')\\\n",
    "        .config('spark.executor.memory','4G')\\\n",
    "        .appName(\"iris\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PySparkShell'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check spark app name\n",
    "spark.sparkContext.appName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.set_option(\"compute.default_index_type\", \"distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print runtime versions\n",
    "# Python version\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark version\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris.csv into Spark dataframe\n",
    "#df = spark.read.csv('file:///vagrant/data/classification_data.csv', header=True, inferSchema=True)\n",
    "psdf = ps.read_csv('data/classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46751, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the data \n",
    "psdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_id                                             object\n",
       "loan_purpose                                        object\n",
       "is_first_loan                                        int32\n",
       "total_credit_card_limit                              int32\n",
       "avg_percentage_credit_card_limit_used_last_year    float64\n",
       "saving_amount                                        int32\n",
       "checking_amount                                      int32\n",
       "is_employed                                          int32\n",
       "yearly_salary                                        int32\n",
       "age                                                  int32\n",
       "dependent_number                                     int32\n",
       "label                                                int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>is_first_loan</th>\n",
       "      <th>total_credit_card_limit</th>\n",
       "      <th>avg_percentage_credit_card_limit_used_last_year</th>\n",
       "      <th>saving_amount</th>\n",
       "      <th>checking_amount</th>\n",
       "      <th>is_employed</th>\n",
       "      <th>yearly_salary</th>\n",
       "      <th>age</th>\n",
       "      <th>dependent_number</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_1</td>\n",
       "      <td>personal</td>\n",
       "      <td>1</td>\n",
       "      <td>7900</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1103</td>\n",
       "      <td>6393</td>\n",
       "      <td>1</td>\n",
       "      <td>16400</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_2</td>\n",
       "      <td>personal</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2588</td>\n",
       "      <td>832</td>\n",
       "      <td>1</td>\n",
       "      <td>75500</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_3</td>\n",
       "      <td>personal</td>\n",
       "      <td>0</td>\n",
       "      <td>7600</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1651</td>\n",
       "      <td>8868</td>\n",
       "      <td>1</td>\n",
       "      <td>59000</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_4</td>\n",
       "      <td>personal</td>\n",
       "      <td>1</td>\n",
       "      <td>3400</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1269</td>\n",
       "      <td>6863</td>\n",
       "      <td>1</td>\n",
       "      <td>26000</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_5</td>\n",
       "      <td>emergency</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1310</td>\n",
       "      <td>3423</td>\n",
       "      <td>1</td>\n",
       "      <td>9700</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loan_id loan_purpose  is_first_loan  total_credit_card_limit  avg_percentage_credit_card_limit_used_last_year  saving_amount  checking_amount  is_employed  yearly_salary  age  dependent_number  label\n",
       "0     A_1     personal              1                     7900                                             0.80           1103             6393            1          16400   42                 4      0\n",
       "1     A_2     personal              0                     3300                                             0.29           2588              832            1          75500   56                 1      0\n",
       "2     A_3     personal              0                     7600                                             0.90           1651             8868            1          59000   46                 1      0\n",
       "3     A_4     personal              1                     3400                                             0.38           1269             6863            1          26000   55                 8      0\n",
       "4     A_5    emergency              0                     2600                                             0.89           1310             3423            1           9700   41                 4      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 rows of Iris dataset\n",
    "psdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_first_loan</th>\n",
       "      <th>total_credit_card_limit</th>\n",
       "      <th>avg_percentage_credit_card_limit_used_last_year</th>\n",
       "      <th>saving_amount</th>\n",
       "      <th>checking_amount</th>\n",
       "      <th>is_employed</th>\n",
       "      <th>yearly_salary</th>\n",
       "      <th>age</th>\n",
       "      <th>dependent_number</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "      <td>46751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.541443</td>\n",
       "      <td>4615.304485</td>\n",
       "      <td>0.700091</td>\n",
       "      <td>2037.636585</td>\n",
       "      <td>3520.671429</td>\n",
       "      <td>0.917328</td>\n",
       "      <td>29527.620800</td>\n",
       "      <td>41.539796</td>\n",
       "      <td>3.744840</td>\n",
       "      <td>0.346538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498285</td>\n",
       "      <td>1890.194454</td>\n",
       "      <td>0.177729</td>\n",
       "      <td>1498.671091</td>\n",
       "      <td>2160.933242</td>\n",
       "      <td>0.275389</td>\n",
       "      <td>16149.757703</td>\n",
       "      <td>12.817646</td>\n",
       "      <td>2.619153</td>\n",
       "      <td>0.475872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>1884.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19200.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1572.000000</td>\n",
       "      <td>3050.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29600.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5900.000000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>2907.000000</td>\n",
       "      <td>4876.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40400.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13500.000000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>10641.000000</td>\n",
       "      <td>13165.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97200.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_first_loan  total_credit_card_limit  avg_percentage_credit_card_limit_used_last_year  saving_amount  checking_amount   is_employed  yearly_salary           age  dependent_number         label\n",
       "count   46751.000000             46751.000000                                     46751.000000   46751.000000     46751.000000  46751.000000   46751.000000  46751.000000      46751.000000  46751.000000\n",
       "mean        0.541443              4615.304485                                         0.700091    2037.636585      3520.671429      0.917328   29527.620800     41.539796          3.744840      0.346538\n",
       "std         0.498285              1890.194454                                         0.177729    1498.671091      2160.933242      0.275389   16149.757703     12.817646          2.619153      0.475872\n",
       "min         0.000000               500.000000                                         0.000000       0.000000         0.000000      0.000000       0.000000     18.000000          0.000000      0.000000\n",
       "25%         0.000000              3200.000000                                         0.580000     920.000000      1884.000000      1.000000   19200.000000     32.000000          2.000000      0.000000\n",
       "50%         1.000000              4500.000000                                         0.710000    1572.000000      3050.000000      1.000000   29600.000000     41.000000          3.000000      0.000000\n",
       "75%         1.000000              5900.000000                                         0.830000    2907.000000      4876.000000      1.000000   40400.000000     50.000000          6.000000      1.000000\n",
       "max         1.000000             13500.000000                                         1.090000   10641.000000     13165.000000      1.000000   97200.000000     79.000000          8.000000      1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory Data Analysis\n",
    "psdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    30550\n",
       "1    16201\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property      11388\n",
       "operations    10580\n",
       "personal      10458\n",
       "emergency      7562\n",
       "others         6763\n",
       "Name: loan_purpose, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.groupBy('loan_purpose').count().show()\n",
    "psdf['loan_purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = psdf.to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_purpose_indexer = StringIndexer(inputCol=\"loan_purpose\", outputCol=\"loan_index\").fit(df)\n",
    "df = loan_purpose_indexer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|loan_purpose|loan_index|\n",
      "+------------+----------+\n",
      "|personal    |2.0       |\n",
      "|personal    |2.0       |\n",
      "|personal    |2.0       |\n",
      "|personal    |2.0       |\n",
      "|emergency   |3.0       |\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['loan_purpose','loan_index']).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_id',\n",
       " 'loan_purpose',\n",
       " 'is_first_loan',\n",
       " 'total_credit_card_limit',\n",
       " 'avg_percentage_credit_card_limit_used_last_year',\n",
       " 'saving_amount',\n",
       " 'checking_amount',\n",
       " 'is_employed',\n",
       " 'yearly_salary',\n",
       " 'age',\n",
       " 'dependent_number',\n",
       " 'label',\n",
       " 'loan_index']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_first_loan',\n",
       " 'total_credit_card_limit',\n",
       " 'avg_percentage_credit_card_limit_used_last_year',\n",
       " 'saving_amount',\n",
       " 'checking_amount',\n",
       " 'is_employed',\n",
       " 'yearly_salary',\n",
       " 'age',\n",
       " 'dependent_number',\n",
       " 'loan_index']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = df.columns[2:-2]\n",
    "feature_cols += ['loan_index']\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- loan_purpose: string (nullable = true)\n",
      " |-- is_first_loan: integer (nullable = true)\n",
      " |-- total_credit_card_limit: integer (nullable = true)\n",
      " |-- avg_percentage_credit_card_limit_used_last_year: double (nullable = true)\n",
      " |-- saving_amount: integer (nullable = true)\n",
      " |-- checking_amount: integer (nullable = true)\n",
      " |-- is_employed: integer (nullable = true)\n",
      " |-- yearly_salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- dependent_number: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- loan_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+-----+\n",
      "|features                                                |label|\n",
      "+--------------------------------------------------------+-----+\n",
      "|[1.0,7900.0,0.8,1103.0,6393.0,1.0,16400.0,42.0,4.0,2.0] |0    |\n",
      "|[0.0,3300.0,0.29,2588.0,832.0,1.0,75500.0,56.0,1.0,2.0] |0    |\n",
      "|[0.0,7600.0,0.9,1651.0,8868.0,1.0,59000.0,46.0,1.0,2.0] |0    |\n",
      "|[1.0,3400.0,0.38,1269.0,6863.0,1.0,26000.0,55.0,8.0,2.0]|0    |\n",
      "|[0.0,2600.0,0.89,1310.0,3423.0,1.0,9700.0,41.0,4.0,3.0] |1    |\n",
      "|[0.0,7600.0,0.51,1040.0,2406.0,1.0,22900.0,52.0,0.0,1.0]|0    |\n",
      "|[1.0,6900.0,0.82,2408.0,5556.0,1.0,34800.0,48.0,4.0,1.0]|0    |\n",
      "|[0.0,5700.0,0.56,1933.0,4139.0,1.0,32500.0,64.0,2.0,2.0]|0    |\n",
      "|[1.0,3400.0,0.95,3866.0,4131.0,1.0,13300.0,23.0,3.0,2.0]|0    |\n",
      "|[0.0,2900.0,0.91,88.0,2725.0,1.0,21100.0,52.0,1.0,2.0]  |1    |\n",
      "+--------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['features','label']).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data for building model\n",
    "model_df=df.select(['features','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data - Train & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Random Forest to train on the training set\n",
    "train_df, test_df = model_df.randomSplit([0.70, 0.30], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32776, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(), len(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13975, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count(), len(test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "model_predictions = rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(10,[1,2,3,4,7],[...|    0|[16.6838849289974...|[0.83419424644987...|       0.0|\n",
      "|(10,[1,2,3,4,7],[...|    0|[19.2409223242261...|[0.96204611621130...|       0.0|\n",
      "|(10,[1,2,3,4,7],[...|    1|[5.52256473103276...|[0.27612823655163...|       1.0|\n",
      "|(10,[1,2,3,4,7],[...|    0|[18.8323430040495...|[0.94161715020247...|       0.0|\n",
      "|[0.0,500.0,0.59,9...|    1|[3.64939484193013...|[0.18246974209650...|       1.0|\n",
      "|[0.0,500.0,0.64,1...|    1|[2.12679355088605...|[0.10633967754430...|       1.0|\n",
      "|[0.0,500.0,0.69,1...|    1|[3.23323701493719...|[0.16166185074685...|       1.0|\n",
      "|[0.0,500.0,0.76,5...|    1|[2.12679355088605...|[0.10633967754430...|       1.0|\n",
      "|[0.0,500.0,0.77,1...|    1|[3.31208121245175...|[0.16560406062258...|       1.0|\n",
      "|[0.0,500.0,0.78,1...|    1|[3.23323701493719...|[0.16166185074685...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print prediction\n",
    "model_predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) to compute AUC\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol='label')\n",
    "rf_auc = evaluator.evaluate(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962829631887776"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = MulticlassClassificationEvaluator(labelCol='label',\n",
    "               metricName='accuracy').evaluate(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The accuracy of RF on test data is 90%'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The accuracy of RF on test data is {0:.0%}'.format(rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramGrid = (ParamGridBuilder()\n",
    "#             .addGrid(rf.maxDepth, [5,10,20,25,30])\n",
    "#             .addGrid(rf.maxBins, [20,30,40 ])\n",
    "#             .addGrid(rf.numTrees, [5, 20,50])\n",
    "#             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [10,20])\n",
    "             .addGrid(rf.maxBins, [20,30])\n",
    "             .addGrid(rf.numTrees, [5,20])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/16 04:44:39 WARN DAGScheduler: Broadcasting large task binary with size 1079.1 KiB\n",
      "21/11/16 04:44:40 WARN DAGScheduler: Broadcasting large task binary with size 1638.9 KiB\n",
      "21/11/16 04:44:41 WARN DAGScheduler: Broadcasting large task binary with size 1108.9 KiB\n",
      "21/11/16 04:44:44 WARN DAGScheduler: Broadcasting large task binary with size 1084.1 KiB\n",
      "21/11/16 04:44:44 WARN DAGScheduler: Broadcasting large task binary with size 1625.6 KiB\n",
      "21/11/16 04:44:45 WARN DAGScheduler: Broadcasting large task binary with size 1124.0 KiB\n",
      "21/11/16 04:44:46 WARN DAGScheduler: Broadcasting large task binary with size 1096.1 KiB\n",
      "21/11/16 04:44:47 WARN DAGScheduler: Broadcasting large task binary with size 1345.1 KiB\n",
      "21/11/16 04:44:47 WARN DAGScheduler: Broadcasting large task binary with size 1581.3 KiB\n",
      "21/11/16 04:44:47 WARN DAGScheduler: Broadcasting large task binary with size 1788.8 KiB\n",
      "21/11/16 04:44:47 WARN DAGScheduler: Broadcasting large task binary with size 1970.8 KiB\n",
      "21/11/16 04:44:47 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:44:48 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:44:48 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:44:48 WARN DAGScheduler: Broadcasting large task binary with size 1462.8 KiB\n",
      "21/11/16 04:44:50 WARN DAGScheduler: Broadcasting large task binary with size 1079.1 KiB\n",
      "21/11/16 04:44:51 WARN DAGScheduler: Broadcasting large task binary with size 1638.9 KiB\n",
      "21/11/16 04:44:51 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:44:52 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "21/11/16 04:44:52 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "21/11/16 04:44:53 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "21/11/16 04:44:53 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "21/11/16 04:44:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n",
      "21/11/16 04:44:55 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n",
      "21/11/16 04:44:56 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n",
      "21/11/16 04:44:56 WARN DAGScheduler: Broadcasting large task binary with size 8.4 MiB\n",
      "21/11/16 04:44:57 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "21/11/16 04:44:58 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "21/11/16 04:44:59 WARN DAGScheduler: Broadcasting large task binary with size 1070.6 KiB\n",
      "21/11/16 04:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1302.9 KiB\n",
      "21/11/16 04:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1526.1 KiB\n",
      "21/11/16 04:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1725.3 KiB\n",
      "21/11/16 04:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1894.1 KiB\n",
      "21/11/16 04:45:00 WARN DAGScheduler: Broadcasting large task binary with size 2032.1 KiB\n",
      "21/11/16 04:45:01 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:45:01 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:45:01 WARN DAGScheduler: Broadcasting large task binary with size 1412.5 KiB\n",
      "21/11/16 04:45:03 WARN DAGScheduler: Broadcasting large task binary with size 1084.1 KiB\n",
      "21/11/16 04:45:04 WARN DAGScheduler: Broadcasting large task binary with size 1625.6 KiB\n",
      "21/11/16 04:45:04 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:45:05 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "21/11/16 04:45:05 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "21/11/16 04:45:06 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "21/11/16 04:45:07 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "21/11/16 04:45:07 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "21/11/16 04:45:08 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/11/16 04:45:09 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "21/11/16 04:45:10 WARN DAGScheduler: Broadcasting large task binary with size 7.9 MiB\n",
      "21/11/16 04:45:10 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n",
      "21/11/16 04:45:11 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "21/11/16 04:45:15 WARN DAGScheduler: Broadcasting large task binary with size 1068.0 KiB\n",
      "21/11/16 04:45:15 WARN DAGScheduler: Broadcasting large task binary with size 1624.2 KiB\n",
      "21/11/16 04:45:16 WARN DAGScheduler: Broadcasting large task binary with size 1095.8 KiB\n",
      "21/11/16 04:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1074.9 KiB\n",
      "21/11/16 04:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1627.1 KiB\n",
      "21/11/16 04:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1137.5 KiB\n",
      "21/11/16 04:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1128.9 KiB\n",
      "21/11/16 04:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1375.8 KiB\n",
      "21/11/16 04:45:22 WARN DAGScheduler: Broadcasting large task binary with size 1615.0 KiB\n",
      "21/11/16 04:45:22 WARN DAGScheduler: Broadcasting large task binary with size 1826.9 KiB\n",
      "21/11/16 04:45:22 WARN DAGScheduler: Broadcasting large task binary with size 2007.6 KiB\n",
      "21/11/16 04:45:22 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:45:22 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:45:22 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:45:23 WARN DAGScheduler: Broadcasting large task binary with size 1471.2 KiB\n",
      "21/11/16 04:45:24 WARN DAGScheduler: Broadcasting large task binary with size 1068.0 KiB\n",
      "21/11/16 04:45:25 WARN DAGScheduler: Broadcasting large task binary with size 1624.2 KiB\n",
      "21/11/16 04:45:25 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:45:26 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "21/11/16 04:45:26 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/11/16 04:45:27 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "21/11/16 04:45:28 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n",
      "21/11/16 04:45:28 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n",
      "21/11/16 04:45:29 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "21/11/16 04:45:30 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "21/11/16 04:45:31 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n",
      "21/11/16 04:45:31 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "21/11/16 04:45:32 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/11/16 04:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1082.4 KiB\n",
      "21/11/16 04:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1315.7 KiB\n",
      "21/11/16 04:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1540.8 KiB\n",
      "21/11/16 04:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1739.8 KiB\n",
      "21/11/16 04:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1907.3 KiB\n",
      "21/11/16 04:45:35 WARN DAGScheduler: Broadcasting large task binary with size 2043.2 KiB\n",
      "21/11/16 04:45:35 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:45:35 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:45:35 WARN DAGScheduler: Broadcasting large task binary with size 1412.0 KiB\n",
      "21/11/16 04:45:37 WARN DAGScheduler: Broadcasting large task binary with size 1074.9 KiB\n",
      "21/11/16 04:45:37 WARN DAGScheduler: Broadcasting large task binary with size 1627.1 KiB\n",
      "21/11/16 04:45:38 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:45:39 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "21/11/16 04:45:39 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "21/11/16 04:45:40 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "21/11/16 04:45:41 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/11/16 04:45:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n",
      "21/11/16 04:45:44 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n",
      "21/11/16 04:45:45 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/11/16 04:45:47 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n",
      "21/11/16 04:45:49 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n",
      "21/11/16 04:45:50 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "21/11/16 04:45:56 WARN DAGScheduler: Broadcasting large task binary with size 1083.7 KiB\n",
      "21/11/16 04:45:57 WARN DAGScheduler: Broadcasting large task binary with size 1646.3 KiB\n",
      "21/11/16 04:45:57 WARN DAGScheduler: Broadcasting large task binary with size 1116.0 KiB\n",
      "21/11/16 04:46:00 WARN DAGScheduler: Broadcasting large task binary with size 1076.7 KiB\n",
      "21/11/16 04:46:01 WARN DAGScheduler: Broadcasting large task binary with size 1628.5 KiB\n",
      "21/11/16 04:46:01 WARN DAGScheduler: Broadcasting large task binary with size 1134.9 KiB\n",
      "21/11/16 04:46:02 WARN DAGScheduler: Broadcasting large task binary with size 1115.5 KiB\n",
      "21/11/16 04:46:03 WARN DAGScheduler: Broadcasting large task binary with size 1362.9 KiB\n",
      "21/11/16 04:46:03 WARN DAGScheduler: Broadcasting large task binary with size 1598.0 KiB\n",
      "21/11/16 04:46:03 WARN DAGScheduler: Broadcasting large task binary with size 1805.8 KiB\n",
      "21/11/16 04:46:03 WARN DAGScheduler: Broadcasting large task binary with size 1986.9 KiB\n",
      "21/11/16 04:46:03 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:46:03 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:46:04 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:46:04 WARN DAGScheduler: Broadcasting large task binary with size 1455.2 KiB\n",
      "21/11/16 04:46:06 WARN DAGScheduler: Broadcasting large task binary with size 1083.7 KiB\n",
      "21/11/16 04:46:06 WARN DAGScheduler: Broadcasting large task binary with size 1646.3 KiB\n",
      "21/11/16 04:46:06 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:46:07 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "21/11/16 04:46:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/11/16 04:46:09 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "21/11/16 04:46:09 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "21/11/16 04:46:10 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n",
      "21/11/16 04:46:11 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "21/11/16 04:46:12 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n",
      "21/11/16 04:46:12 WARN DAGScheduler: Broadcasting large task binary with size 8.4 MiB\n",
      "21/11/16 04:46:13 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "21/11/16 04:46:14 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/11/16 04:46:15 WARN DAGScheduler: Broadcasting large task binary with size 1054.8 KiB\n",
      "21/11/16 04:46:15 WARN DAGScheduler: Broadcasting large task binary with size 1278.5 KiB\n",
      "21/11/16 04:46:16 WARN DAGScheduler: Broadcasting large task binary with size 1494.2 KiB\n",
      "21/11/16 04:46:16 WARN DAGScheduler: Broadcasting large task binary with size 1692.1 KiB\n",
      "21/11/16 04:46:16 WARN DAGScheduler: Broadcasting large task binary with size 1862.4 KiB\n",
      "21/11/16 04:46:16 WARN DAGScheduler: Broadcasting large task binary with size 1999.0 KiB\n",
      "21/11/16 04:46:16 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:46:17 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:46:17 WARN DAGScheduler: Broadcasting large task binary with size 1386.4 KiB\n",
      "21/11/16 04:46:19 WARN DAGScheduler: Broadcasting large task binary with size 1076.7 KiB\n",
      "21/11/16 04:46:19 WARN DAGScheduler: Broadcasting large task binary with size 1628.5 KiB\n",
      "21/11/16 04:46:20 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:46:20 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "21/11/16 04:46:21 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "21/11/16 04:46:21 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "21/11/16 04:46:22 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "21/11/16 04:46:23 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n",
      "21/11/16 04:46:24 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/11/16 04:46:24 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "21/11/16 04:46:25 WARN DAGScheduler: Broadcasting large task binary with size 7.9 MiB\n",
      "21/11/16 04:46:26 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n",
      "21/11/16 04:46:27 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "21/11/16 04:46:30 WARN DAGScheduler: Broadcasting large task binary with size 1077.8 KiB\n",
      "21/11/16 04:46:31 WARN DAGScheduler: Broadcasting large task binary with size 1645.8 KiB\n",
      "21/11/16 04:46:31 WARN DAGScheduler: Broadcasting large task binary with size 1125.5 KiB\n",
      "21/11/16 04:46:34 WARN DAGScheduler: Broadcasting large task binary with size 1049.4 KiB\n",
      "21/11/16 04:46:34 WARN DAGScheduler: Broadcasting large task binary with size 1582.9 KiB\n",
      "21/11/16 04:46:35 WARN DAGScheduler: Broadcasting large task binary with size 1103.7 KiB\n",
      "21/11/16 04:46:36 WARN DAGScheduler: Broadcasting large task binary with size 1103.1 KiB\n",
      "21/11/16 04:46:36 WARN DAGScheduler: Broadcasting large task binary with size 1347.2 KiB\n",
      "21/11/16 04:46:37 WARN DAGScheduler: Broadcasting large task binary with size 1587.6 KiB\n",
      "21/11/16 04:46:37 WARN DAGScheduler: Broadcasting large task binary with size 1807.1 KiB\n",
      "21/11/16 04:46:37 WARN DAGScheduler: Broadcasting large task binary with size 2000.3 KiB\n",
      "21/11/16 04:46:37 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:46:37 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:46:38 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:46:38 WARN DAGScheduler: Broadcasting large task binary with size 1460.2 KiB\n",
      "21/11/16 04:46:39 WARN DAGScheduler: Broadcasting large task binary with size 1077.8 KiB\n",
      "21/11/16 04:46:40 WARN DAGScheduler: Broadcasting large task binary with size 1645.8 KiB\n",
      "21/11/16 04:46:40 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:46:41 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "21/11/16 04:46:41 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/11/16 04:46:42 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "21/11/16 04:46:43 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n",
      "21/11/16 04:46:43 WARN DAGScheduler: Broadcasting large task binary with size 6.9 MiB\n",
      "21/11/16 04:46:44 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "21/11/16 04:46:45 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "21/11/16 04:46:45 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n",
      "21/11/16 04:46:46 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "21/11/16 04:46:47 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/11/16 04:46:48 WARN DAGScheduler: Broadcasting large task binary with size 1063.5 KiB\n",
      "21/11/16 04:46:48 WARN DAGScheduler: Broadcasting large task binary with size 1297.0 KiB\n",
      "21/11/16 04:46:49 WARN DAGScheduler: Broadcasting large task binary with size 1517.7 KiB\n",
      "21/11/16 04:46:49 WARN DAGScheduler: Broadcasting large task binary with size 1716.3 KiB\n",
      "21/11/16 04:46:49 WARN DAGScheduler: Broadcasting large task binary with size 1880.6 KiB\n",
      "21/11/16 04:46:49 WARN DAGScheduler: Broadcasting large task binary with size 2015.5 KiB\n",
      "21/11/16 04:46:49 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:46:49 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:46:50 WARN DAGScheduler: Broadcasting large task binary with size 1391.7 KiB\n",
      "21/11/16 04:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1049.4 KiB\n",
      "21/11/16 04:46:52 WARN DAGScheduler: Broadcasting large task binary with size 1582.9 KiB\n",
      "21/11/16 04:46:52 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:46:53 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "21/11/16 04:46:53 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "21/11/16 04:46:54 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "21/11/16 04:46:55 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "21/11/16 04:46:55 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n",
      "21/11/16 04:46:56 WARN DAGScheduler: Broadcasting large task binary with size 7.1 MiB\n",
      "21/11/16 04:46:57 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "21/11/16 04:46:57 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n",
      "21/11/16 04:46:58 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/11/16 04:46:59 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "21/11/16 04:47:03 WARN DAGScheduler: Broadcasting large task binary with size 1057.5 KiB\n",
      "21/11/16 04:47:03 WARN DAGScheduler: Broadcasting large task binary with size 1610.1 KiB\n",
      "21/11/16 04:47:03 WARN DAGScheduler: Broadcasting large task binary with size 1088.8 KiB\n",
      "21/11/16 04:47:06 WARN DAGScheduler: Broadcasting large task binary with size 1062.7 KiB\n",
      "21/11/16 04:47:06 WARN DAGScheduler: Broadcasting large task binary with size 1610.5 KiB\n",
      "21/11/16 04:47:07 WARN DAGScheduler: Broadcasting large task binary with size 1112.2 KiB\n",
      "21/11/16 04:47:08 WARN DAGScheduler: Broadcasting large task binary with size 1129.6 KiB\n",
      "21/11/16 04:47:08 WARN DAGScheduler: Broadcasting large task binary with size 1381.3 KiB\n",
      "21/11/16 04:47:09 WARN DAGScheduler: Broadcasting large task binary with size 1613.1 KiB\n",
      "21/11/16 04:47:09 WARN DAGScheduler: Broadcasting large task binary with size 1820.2 KiB\n",
      "21/11/16 04:47:09 WARN DAGScheduler: Broadcasting large task binary with size 1996.4 KiB\n",
      "21/11/16 04:47:09 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:47:09 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:47:09 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:47:10 WARN DAGScheduler: Broadcasting large task binary with size 1459.4 KiB\n",
      "21/11/16 04:47:11 WARN DAGScheduler: Broadcasting large task binary with size 1057.5 KiB\n",
      "21/11/16 04:47:12 WARN DAGScheduler: Broadcasting large task binary with size 1610.1 KiB\n",
      "21/11/16 04:47:12 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:47:13 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "21/11/16 04:47:13 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/11/16 04:47:14 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "21/11/16 04:47:15 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "21/11/16 04:47:15 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n",
      "21/11/16 04:47:16 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "21/11/16 04:47:17 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n",
      "21/11/16 04:47:17 WARN DAGScheduler: Broadcasting large task binary with size 8.4 MiB\n",
      "21/11/16 04:47:18 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "21/11/16 04:47:19 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/11/16 04:47:21 WARN DAGScheduler: Broadcasting large task binary with size 1097.1 KiB\n",
      "21/11/16 04:47:21 WARN DAGScheduler: Broadcasting large task binary with size 1331.4 KiB\n",
      "21/11/16 04:47:21 WARN DAGScheduler: Broadcasting large task binary with size 1552.2 KiB\n",
      "21/11/16 04:47:21 WARN DAGScheduler: Broadcasting large task binary with size 1747.0 KiB\n",
      "21/11/16 04:47:21 WARN DAGScheduler: Broadcasting large task binary with size 1917.0 KiB\n",
      "21/11/16 04:47:21 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "21/11/16 04:47:22 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "21/11/16 04:47:22 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "21/11/16 04:47:22 WARN DAGScheduler: Broadcasting large task binary with size 1423.5 KiB\n",
      "21/11/16 04:47:24 WARN DAGScheduler: Broadcasting large task binary with size 1062.7 KiB\n",
      "21/11/16 04:47:24 WARN DAGScheduler: Broadcasting large task binary with size 1610.5 KiB\n",
      "21/11/16 04:47:24 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "21/11/16 04:47:25 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "21/11/16 04:47:26 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "21/11/16 04:47:26 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "21/11/16 04:47:27 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "21/11/16 04:47:28 WARN DAGScheduler: Broadcasting large task binary with size 6.5 MiB\n",
      "21/11/16 04:47:28 WARN DAGScheduler: Broadcasting large task binary with size 7.1 MiB\n",
      "21/11/16 04:47:29 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "21/11/16 04:47:30 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "21/11/16 04:47:30 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/11/16 04:47:31 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "21/11/16 04:47:34 WARN DAGScheduler: Broadcasting large task binary with size 1105.2 KiB\n",
      "21/11/16 04:47:34 WARN DAGScheduler: Broadcasting large task binary with size 1717.6 KiB\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "cv_model = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Param(maxDepth): 10'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Best Param(maxDepth): {best_rf_model._java_obj.getMaxDepth()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Param(maxBins): 30'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Best Param(maxBins): {best_rf_model._java_obj.getMaxBins()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Param(NumTrees): 20'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Best Param(NumTrees): {best_rf_model._java_obj.getNumTrees()}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for entire dataset\n",
    "model_predictions = best_rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/16 04:53:10 WARN DAGScheduler: Broadcasting large task binary with size 1170.7 KiB\n"
     ]
    }
   ],
   "source": [
    "best_rf_auc = evaluator.evaluate(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9690665508778045"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/16 04:53:17 WARN DAGScheduler: Broadcasting large task binary with size 1177.9 KiB\n"
     ]
    }
   ],
   "source": [
    "true_pos=model_predictions.filter(model_predictions['label']==1).filter(model_predictions['prediction']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pos=model_predictions.filter(model_predictions['label']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/16 04:53:20 WARN DAGScheduler: Broadcasting large task binary with size 1180.1 KiB\n"
     ]
    }
   ],
   "source": [
    "pred_pos=model_predictions.filter(model_predictions['prediction']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9105196982397318"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall \n",
    "float(true_pos)/(actual_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849960876369327"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision on test Data \n",
    "float(true_pos)/(pred_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
