{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bdse111.example.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://bdse111.example.com:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1fa01a7970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SparkSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.types import StringType,DoubleType,IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for standalone pyspark\n",
    "# create spar session object\n",
    "spark=SparkSession.builder.appName('data_processing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PySparkShell'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.appName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv Dataset \n",
    "df=spark.read.csv('data/sample_data.csv',inferSchema=True,header=True)\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratings', 'age', 'experience', 'family', 'mobile']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns of dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of dataset\n",
    "df.count(),len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ratings: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: double (nullable = true)\n",
      " |-- family: integer (nullable = true)\n",
      " |-- mobile: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print dataframe schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+\n",
      "|ratings|age|experience|family| mobile|\n",
      "+-------+---+----------+------+-------+\n",
      "|      3| 32|       9.0|     3|   Vivo|\n",
      "|      3| 27|      13.0|     3|  Apple|\n",
      "|      4| 22|       2.5|     0|Samsung|\n",
      "|      4| 37|      16.5|     4|  Apple|\n",
      "|      5| 27|       9.0|     1|     MI|\n",
      "|      4| 27|       9.0|     0|   Oppo|\n",
      "|      5| 37|      23.0|     5|   Vivo|\n",
      "|      5| 37|      23.0|     5|Samsung|\n",
      "|      3| 22|       2.5|     0|  Apple|\n",
      "|      3| 27|       6.0|     0|     MI|\n",
      "|      2| 27|       6.0|     2|   Oppo|\n",
      "|      5| 27|       6.0|     2|Samsung|\n",
      "|      3| 37|      16.5|     5|  Apple|\n",
      "|      5| 27|       6.0|     0|     MI|\n",
      "|      4| 22|       6.0|     1|   Oppo|\n",
      "|      4| 37|       9.0|     2|Samsung|\n",
      "|      4| 27|       6.0|     1|  Apple|\n",
      "|      1| 37|      23.0|     5|     MI|\n",
      "|      2| 42|      23.0|     2|   Oppo|\n",
      "|      4| 37|       6.0|     0|   Vivo|\n",
      "+-------+---+----------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display fisrt few rows of dataframe\n",
    "df.show()\n",
    "#df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| mobile|count|\n",
      "+-------+-----+\n",
      "|     MI|    8|\n",
      "|   Oppo|    7|\n",
      "|Samsung|    6|\n",
      "|   Vivo|    5|\n",
      "|  Apple|    7|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by one column\n",
    "df.groupBy('mobile').count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| mobile|count|\n",
      "+-------+-----+\n",
      "|     MI|    8|\n",
      "|  Apple|    7|\n",
      "|   Oppo|    7|\n",
      "|Samsung|    6|\n",
      "|   Vivo|    5|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort value counts\n",
    "df.groupBy('mobile').count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+\n",
      "| mobile|      avg(ratings)|          avg(age)|   avg(experience)|       avg(family)|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|     MI|               3.5|            30.125|           10.1875|             1.375|\n",
      "|   Oppo| 2.857142857142857|28.428571428571427|10.357142857142858|1.4285714285714286|\n",
      "|Samsung| 4.166666666666667|28.666666666666668| 8.666666666666666|1.8333333333333333|\n",
      "|   Vivo|               4.2|              36.0|              11.4|               1.8|\n",
      "|  Apple|3.4285714285714284|30.571428571428573|              11.0|2.7142857142857144|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate statistical measures\n",
    "df.groupBy('mobile').mean().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+---------------+-----------+\n",
      "| mobile|sum(ratings)|sum(age)|sum(experience)|sum(family)|\n",
      "+-------+------------+--------+---------------+-----------+\n",
      "|     MI|          28|     241|           81.5|         11|\n",
      "|   Oppo|          20|     199|           72.5|         10|\n",
      "|Samsung|          25|     172|           52.0|         11|\n",
      "|   Vivo|          21|     180|           57.0|          9|\n",
      "|  Apple|          24|     214|           77.0|         19|\n",
      "+-------+------------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate statistical measures\n",
    "df.groupBy('mobile').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+---------------+-----------+\n",
      "| mobile|max(ratings)|max(age)|max(experience)|max(family)|\n",
      "+-------+------------+--------+---------------+-----------+\n",
      "|     MI|           5|      42|           23.0|          5|\n",
      "|   Oppo|           4|      42|           23.0|          2|\n",
      "|Samsung|           5|      37|           23.0|          5|\n",
      "|   Vivo|           5|      37|           23.0|          5|\n",
      "|  Apple|           4|      37|           16.5|          5|\n",
      "+-------+------------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate statistical measures\n",
    "df.groupBy('mobile').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+---------------+-----------+\n",
      "| mobile|min(ratings)|min(age)|min(experience)|min(family)|\n",
      "+-------+------------+--------+---------------+-----------+\n",
      "|     MI|           1|      27|            2.5|          0|\n",
      "|   Oppo|           2|      22|            6.0|          0|\n",
      "|Samsung|           2|      22|            2.5|          0|\n",
      "|   Vivo|           3|      32|            6.0|          0|\n",
      "|  Apple|           3|      22|            2.5|          0|\n",
      "+-------+------------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate statistical measures\n",
    "df.groupBy('mobile').min().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| mobile|count|\n",
      "+-------+-----+\n",
      "|     MI|    8|\n",
      "|   Oppo|    7|\n",
      "|Samsung|    6|\n",
      "|   Vivo|    5|\n",
      "|  Apple|    7|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use spark sql\n",
    "spark.sql('''select mobile, count(*) as count from dfTable\n",
    "        group by mobile''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------+\n",
      "| mobile|min(experience)|min(age)|\n",
      "+-------+---------------+--------+\n",
      "|     MI|            2.5|      27|\n",
      "|   Oppo|            6.0|      22|\n",
      "|Samsung|            2.5|      22|\n",
      "|   Vivo|            6.0|      32|\n",
      "|  Apple|            2.5|      22|\n",
      "+-------+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use spark sql\n",
    "spark.sql('''select mobile, min(experience), min(age) from dfTable\n",
    "        group by mobile''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation\n",
    "df.groupBy('mobile').agg({'experience':'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv Dataset\n",
    "rtdf=spark.read.csv('data/online_retail_dataset.csv',inferSchema=True,header=True)\n",
    "rtdf.createOrReplaceTempView(\"rtTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of dataframe\n",
    "rtdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of dataset\n",
    "rtdf.count(),len(rtdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataframe schema\n",
    "rtdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display fisrt few rows of dataframe\n",
    "rtdf.show()\n",
    "#rtdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting\n",
    "rtdf.select(fn.count('StockCode')).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct count\n",
    "rtdf.select(fn.countDistinct('StockCode')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimun and maximun\n",
    "rtdf.select(fn.min(\"Quantity\"), fn.max(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance and Standard Deviation\n",
    "rtdf.select(fn.var_pop('Quantity'), fn.var_samp('Quantity'),\n",
    "        fn.stddev_pop('Quantity'), fn.stddev_samp('Quantity')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sql\n",
    "spark.sql('''select count(StockCode) from rtTable''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance and Correlation\n",
    "rtdf.select(fn.corr('InvoiceNo', 'Quantity'), fn.covar_samp('InvoiceNo', 'Quantity'),\n",
    "        fn.covar_pop('InvoiceNo', 'Quantity')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count with groupby\n",
    "rtdf.groupBy(\"InvoiceNo\", \"CustomerId\").count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg function\n",
    "rtdf.groupBy('InvoiceNo').agg({'Quantity':'count'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg function\n",
    "rtdf.groupBy('InvoiceNo').agg(fn.count('Quantity').alias('quan'),\n",
    "        fn.expr('count(Quantity)')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg function\n",
    "rtdf.groupBy('InvoiceNo').agg({'Quantity':'min', 'UnitPrice':'max'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg function\n",
    "rtdf.groupBy('InvoiceNo').agg(fn.max('Quantity'),\n",
    "        fn.min('Quantity')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal function \n",
    "def price_range(brand):\n",
    "    if brand in ['Samsung','Apple']:\n",
    "        return 'High Price'\n",
    "    elif brand =='MI':\n",
    "        return 'Mid Price'\n",
    "    else:\n",
    "        return 'Low Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create udf using python function\n",
    "brand_udf=udf(price_range,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply udf on dataframe\n",
    "df.withColumn('price_range',brand_udf(df['mobile'])).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lambda function\n",
    "age_udf = udf(lambda age: \"young\" if age <= 30 else \"senior\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply udf on dataframe\n",
    "df.withColumn(\"age_group\", age_udf(df.age)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas UDF (Spark 2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create python function\n",
    "def remaining_yrs(age):\n",
    "    yrs_left=100-age\n",
    "    return yrs_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create udf using python function\n",
    "length_udf = pandas_udf(remaining_yrs, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pandas udf on dataframe\n",
    "df.withColumn('yrs_left', length_udf(df['age'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use decorator\n",
    "@pandas_udf(IntegerType())\n",
    "def remaining_yrs2(age):\n",
    "    yrs_left=100-age\n",
    "    return yrs_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pandas udf on dataframe\n",
    "df.withColumn('yrs_left', remaining_yrs2(df['age'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf using two columns \n",
    "def prod(rating,exp):\n",
    "    x=rating*exp\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create udf using python function\n",
    "prod_udf = pandas_udf(prod, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pandas udf on multiple columns of dataframe\n",
    "df.withColumn(\"product\", prod_udf(df['ratings'],df['experience'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use decorator\n",
    "@pandas_udf(DoubleType())\n",
    "def prod2(rating,exp):\n",
    "    x=rating*exp\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+-------+-------+\n",
      "|ratings|age|experience|family| mobile|product|\n",
      "+-------+---+----------+------+-------+-------+\n",
      "|      3| 32|       9.0|     3|   Vivo|   27.0|\n",
      "|      3| 27|      13.0|     3|  Apple|   39.0|\n",
      "|      4| 22|       2.5|     0|Samsung|   10.0|\n",
      "|      4| 37|      16.5|     4|  Apple|   66.0|\n",
      "|      5| 27|       9.0|     1|     MI|   45.0|\n",
      "+-------+---+----------+------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply pandas udf on multiple columns of dataframe\n",
    "df.withColumn(\"product\", prod2(df['ratings'],df['experience'])).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas UDF (Spark 3.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas udf function\n",
    "@pandas_udf('int')\n",
    "def remaining_yrs3(age: pd.Series) -> pd.Series:\n",
    "    yrs_left=100-age\n",
    "    return yrs_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pandas udf on dataframe\n",
    "df.withColumn('yrs_left', remaining_yrs3(df['age'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas udf function\n",
    "@pandas_udf('double')\n",
    "def prod3(rating: pd.Series, exp: pd.Series) -> pd.Series:\n",
    "    x=rating*exp\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pandas udf on multiple columns of dataframe\n",
    "df.withColumn(\"product\", prod3(df['ratings'],df['experience'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use spark sql \n",
    "df.selectExpr('*', 'experience*ratings as product').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the dataframe as single csv \n",
    "df.coalesce(1).write.csv('data/df_data.csv', header='True', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into parquet format \n",
    "rtdf.write.parquet('data/retail_dataset_parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from parquet format \n",
    "rtdf2=spark.read.parquet('data/retail_dataset_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdf2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = spark.read.csv('data/winequality_white.csv',sep=';',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of dataframe\n",
    "wdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of dataset\n",
    "wdf.count(),len(wdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataframe schema\n",
    "wdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display fisrt few rows of dataframe\n",
    "#wdf.show()\n",
    "wdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf.select('pH','sulphates','chlorides').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas udf function\n",
    "# to detect outlier\n",
    "@pandas_udf('int')\n",
    "def outliers_iqr(val: pd.Series) -> pd.Series:\n",
    "    quartile_1, quartile_3 = np.percentile(val, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    \n",
    "    return pd.Series(np.where((val > upper_bound) | (val < lower_bound),1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2 = wdf.withColumn('pH_out', outliers_iqr(wdf['pH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2.cache() # 更新\n",
    "wdf2.createOrReplaceTempView(\"wdf2Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2.select('pH','pH_out').filter('pH_out==1').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''select pH,pH_out from wdf2Table where pH_out=1 limit 10''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into parquet format \n",
    "wdf2.write.csv('data/wdf2', header='True', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv Dataset\n",
    "wdf3=spark.read.csv('data/wdf2',inferSchema=True,header=True)\n",
    "wdf3.createOrReplaceTempView(\"wdf4Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf3.filter('pH_out==1').show(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
